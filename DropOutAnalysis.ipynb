{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c15eec1-c7f5-4ac7-812f-8f0b965cefba",
   "metadata": {},
   "source": [
    "# University Student Dropout Prediction Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425bf7a1-6f31-4126-9b2e-912e44642068",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this project, we aim to develop a machine learning model to predict the likelihood of university students dropping out. The challenge of student dropouts is a critical issue in higher education, impacting both the students' future and the educational institutions' effectiveness. Through predictive modeling, we seek to understand the key factors influencing dropout rates and identify at-risk students early in their academic journey."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9431d26-b335-4556-996e-5fda6897afd5",
   "metadata": {},
   "source": [
    "### Project Objectives:\n",
    "\n",
    "1. **Data Collection:** Acquire comprehensive and relevant datasets from universities, encompassing various factors like student demographics, academic records, engagement levels, and more.\n",
    "2. **Data Preprocessing:** Clean and preprocess the data to ensure accuracy and reliability for our predictive analysis.\n",
    "3. **Exploratory Data Analysis (EDA):** Perform in-depth analysis to uncover trends and insights within the data, guiding our feature selection and modeling approach.\n",
    "4.  **Development:** Construct a predictive model utilizing mehtods such as Random Forest, XGBoost, Gradient Boosting, and Feed-forward Neural Networks, leveraging their combined strengths.\n",
    "5. **Model Evaluation and Tuning:** Utilize relevant performance metrics to evaluate and refine the model, aiming for enhanced predictive accuracy and robustness.\n",
    "6. **Interpretation and Reporting:** Interpret the results to provide meaningful insights and recommendations, focusing on strategies to improve student retention rates at the university level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35d5057-3c68-40c7-8b6e-ff53a819aa86",
   "metadata": {},
   "source": [
    "## 1. Data Collection:\n",
    "\n",
    "**Sources Include:**\n",
    "University requested student drop out data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a65927-53dc-455c-ae28-bd8d71f511bb",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "166baa13-8190-4ff4-ab46-1c7a2a764f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing essential libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e8f73ce-82e6-40a9-9c68-55e5876f3505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIDM</th>\n",
       "      <th>Cohort</th>\n",
       "      <th>SEX</th>\n",
       "      <th>Degree</th>\n",
       "      <th>Major 1</th>\n",
       "      <th>1st Year GPA</th>\n",
       "      <th>Dorm</th>\n",
       "      <th>1st Year Retention</th>\n",
       "      <th>College</th>\n",
       "      <th>Total Earned Hours</th>\n",
       "      <th>SAT</th>\n",
       "      <th>Major 2</th>\n",
       "      <th>Advisor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>202109F</td>\n",
       "      <td>M</td>\n",
       "      <td>BS</td>\n",
       "      <td>Mechanical Engineering</td>\n",
       "      <td>2.49</td>\n",
       "      <td>Campion Hall</td>\n",
       "      <td>1</td>\n",
       "      <td>SEC</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>202109F</td>\n",
       "      <td>M</td>\n",
       "      <td>BS</td>\n",
       "      <td>Biology</td>\n",
       "      <td>3.18</td>\n",
       "      <td>Commuter</td>\n",
       "      <td>1</td>\n",
       "      <td>CAS</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>202109F</td>\n",
       "      <td>M</td>\n",
       "      <td>BS</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>2.86</td>\n",
       "      <td>Regis Hall</td>\n",
       "      <td>1</td>\n",
       "      <td>CAS</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>202109F</td>\n",
       "      <td>M</td>\n",
       "      <td>BS</td>\n",
       "      <td>DSB Undeclared</td>\n",
       "      <td>3.84</td>\n",
       "      <td>Gonzaga Hall</td>\n",
       "      <td>1</td>\n",
       "      <td>DSB</td>\n",
       "      <td>45</td>\n",
       "      <td>1300.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>202109F</td>\n",
       "      <td>M</td>\n",
       "      <td>BS</td>\n",
       "      <td>Management</td>\n",
       "      <td>2.69</td>\n",
       "      <td>Commuter</td>\n",
       "      <td>1</td>\n",
       "      <td>DSB</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PIDM   Cohort SEX Degree                 Major 1  1st Year GPA  \\\n",
       "0     1  202109F   M     BS  Mechanical Engineering          2.49   \n",
       "1     2  202109F   M     BS                 Biology          3.18   \n",
       "2     3  202109F   M     BS               Chemistry          2.86   \n",
       "3     4  202109F   M     BS          DSB Undeclared          3.84   \n",
       "4     5  202109F   M     BS              Management          2.69   \n",
       "\n",
       "           Dorm  1st Year Retention College  Total Earned Hours     SAT  \\\n",
       "0  Campion Hall                   1     SEC                  36     NaN   \n",
       "1      Commuter                   1     CAS                  47     NaN   \n",
       "2    Regis Hall                   1     CAS                  46     NaN   \n",
       "3  Gonzaga Hall                   1     DSB                  45  1300.0   \n",
       "4      Commuter                   1     DSB                  42     NaN   \n",
       "\n",
       "  Major 2  Advisor  \n",
       "0     NaN      1.0  \n",
       "1     NaN      2.0  \n",
       "2     NaN      3.0  \n",
       "3     NaN      4.0  \n",
       "4     NaN      5.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/kflemming30/Student-Drop-Out-Prediction/main/OIR_Student%20Data%20Request.csv\"\n",
    "student_df = pd.read_csv(url)\n",
    "student_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b31c2eba-3e5b-4e86-93d3-f57ab33741f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2584, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cbbbb6e-089a-4fae-b149-84380026e4fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PIDM', 'Cohort', 'SEX', 'Degree', 'Major 1', '1st Year GPA', 'Dorm',\n",
       "       '1st Year Retention', 'College', 'Total Earned Hours', 'SAT', 'Major 2',\n",
       "       'Advisor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8318dee6-9e51-4095-ad02-674a313c4e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202209F    1328\n",
       "202109F    1256\n",
       "Name: Cohort, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df['Cohort'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec8d6bb1-ecd0-4528-a14f-a3837fc487a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with hardly any data won't be useful in the modeling\n",
    "student_df = student_df.drop(['SAT', 'Major 2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a4c629-6829-4c91-b7ce-584ee30f425b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the leftover rows that have no GPA or Advisor\n",
    "student_df = student_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad5d466f-1b30-4a4f-9130-32027d108849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2575 entries, 0 to 2583\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   PIDM                2575 non-null   int64  \n",
      " 1   Cohort              2575 non-null   object \n",
      " 2   SEX                 2575 non-null   object \n",
      " 3   Degree              2575 non-null   object \n",
      " 4   Major 1             2575 non-null   object \n",
      " 5   1st Year GPA        2575 non-null   float64\n",
      " 6   Dorm                2575 non-null   object \n",
      " 7   1st Year Retention  2575 non-null   int64  \n",
      " 8   College             2575 non-null   object \n",
      " 9   Total Earned Hours  2575 non-null   int64  \n",
      " 10  Advisor             2575 non-null   float64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 241.4+ KB\n"
     ]
    }
   ],
   "source": [
    "student_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c61839-0c40-4d50-89f3-4b21000a08af",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8dccfac0-f837-42a0-a5fc-d8ab0be3711f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2334\n",
       "0     241\n",
       "Name: 1st Year Retention, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df['1st Year Retention'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb3f177a-33c5-4ae9-919d-69c80618d159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIDM</th>\n",
       "      <th>1st Year GPA</th>\n",
       "      <th>1st Year Retention</th>\n",
       "      <th>Total Earned Hours</th>\n",
       "      <th>Advisor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2575.000000</td>\n",
       "      <td>2575.000000</td>\n",
       "      <td>2575.000000</td>\n",
       "      <td>2575.000000</td>\n",
       "      <td>2575.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1292.469903</td>\n",
       "      <td>3.362144</td>\n",
       "      <td>0.906408</td>\n",
       "      <td>46.012427</td>\n",
       "      <td>56.577476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>746.134354</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.291317</td>\n",
       "      <td>9.756507</td>\n",
       "      <td>47.140717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>646.500000</td>\n",
       "      <td>3.110000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1293.000000</td>\n",
       "      <td>3.490000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>53.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1938.500000</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>88.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2584.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PIDM  1st Year GPA  1st Year Retention  Total Earned Hours  \\\n",
       "count  2575.000000   2575.000000         2575.000000         2575.000000   \n",
       "mean   1292.469903      3.362144            0.906408           46.012427   \n",
       "std     746.134354      0.545620            0.291317            9.756507   \n",
       "min       1.000000      0.000000            0.000000            0.000000   \n",
       "25%     646.500000      3.110000            1.000000           45.000000   \n",
       "50%    1293.000000      3.490000            1.000000           46.000000   \n",
       "75%    1938.500000      3.750000            1.000000           51.000000   \n",
       "max    2584.000000      4.000000            1.000000           81.000000   \n",
       "\n",
       "           Advisor  \n",
       "count  2575.000000  \n",
       "mean     56.577476  \n",
       "std      47.140717  \n",
       "min       0.000000  \n",
       "25%      11.000000  \n",
       "50%      53.000000  \n",
       "75%      88.000000  \n",
       "max     166.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "288e4d07-a5d8-4803-803b-ee2096103ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2575 entries, 0 to 2583\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   PIDM                2575 non-null   int64  \n",
      " 1   Cohort              2575 non-null   object \n",
      " 2   SEX                 2575 non-null   object \n",
      " 3   Degree              2575 non-null   object \n",
      " 4   Major 1             2575 non-null   object \n",
      " 5   1st Year GPA        2575 non-null   float64\n",
      " 6   Dorm                2575 non-null   object \n",
      " 7   1st Year Retention  2575 non-null   int64  \n",
      " 8   College             2575 non-null   object \n",
      " 9   Total Earned Hours  2575 non-null   int64  \n",
      " 10  Advisor             2575 non-null   float64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 241.4+ KB\n"
     ]
    }
   ],
   "source": [
    "student_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e63e681c-53a6-4464-bdfb-57677bca7401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "College\n",
       "CAS     0.894220\n",
       "DSB     0.905694\n",
       "EGAN    0.931398\n",
       "SEC     0.922581\n",
       "Name: 1st Year Retention, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df.groupby('College')['1st Year Retention'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3264913d-ae23-44c3-b2a9-d4bbc69ff76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count of Students Retention</th>\n",
       "      <th>Mean 1st Year Retention</th>\n",
       "      <th>Mean Total Earned Hours</th>\n",
       "      <th>Mean 1st Year GPA</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dorm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1036 North Benson Road</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>3.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Commuter</th>\n",
       "      <td>81</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>46.802469</td>\n",
       "      <td>3.237531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jogues Hall</th>\n",
       "      <td>619</td>\n",
       "      <td>0.922456</td>\n",
       "      <td>47.962843</td>\n",
       "      <td>3.443441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Campion Hall</th>\n",
       "      <td>493</td>\n",
       "      <td>0.920892</td>\n",
       "      <td>47.561866</td>\n",
       "      <td>3.319452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gonzaga Hall</th>\n",
       "      <td>402</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>45.101990</td>\n",
       "      <td>3.350896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Regis Hall</th>\n",
       "      <td>583</td>\n",
       "      <td>0.900515</td>\n",
       "      <td>44.780446</td>\n",
       "      <td>3.342607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loyola Hall</th>\n",
       "      <td>394</td>\n",
       "      <td>0.860406</td>\n",
       "      <td>43.677665</td>\n",
       "      <td>3.352259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claver Hall</th>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>35.500000</td>\n",
       "      <td>3.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Count of Students Retention  Mean 1st Year Retention  \\\n",
       "Dorm                                                                           \n",
       "1036 North Benson Road                            1                 1.000000   \n",
       "Commuter                                         81                 0.925926   \n",
       "Jogues Hall                                     619                 0.922456   \n",
       "Campion Hall                                    493                 0.920892   \n",
       "Gonzaga Hall                                    402                 0.915423   \n",
       "Regis Hall                                      583                 0.900515   \n",
       "Loyola Hall                                     394                 0.860406   \n",
       "Claver Hall                                       2                 0.500000   \n",
       "\n",
       "                        Mean Total Earned Hours  Mean 1st Year GPA  \n",
       "Dorm                                                                \n",
       "1036 North Benson Road                36.000000           3.690000  \n",
       "Commuter                              46.802469           3.237531  \n",
       "Jogues Hall                           47.962843           3.443441  \n",
       "Campion Hall                          47.561866           3.319452  \n",
       "Gonzaga Hall                          45.101990           3.350896  \n",
       "Regis Hall                            44.780446           3.342607  \n",
       "Loyola Hall                           43.677665           3.352259  \n",
       "Claver Hall                           35.500000           3.510000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by Dorm and calculate mean retention, mean total earned hours, and mean 1st year GPA, along with counts\n",
    "retention_mean_count = student_df.groupby('Dorm')['1st Year Retention'].agg(['count', 'mean']).sort_values(by='mean', ascending=False)\n",
    "earned_hours_mean = student_df.groupby('Dorm')['Total Earned Hours'].mean().sort_values(ascending=False)\n",
    "gpa_mean = student_df.groupby('Dorm')['1st Year GPA'].mean().sort_values(ascending=False)\n",
    "\n",
    "# Merge the three Series on Dorm\n",
    "result = pd.concat([retention_mean_count, earned_hours_mean, gpa_mean], axis=1)\n",
    "\n",
    "# Add clarity to column names\n",
    "result.columns = ['Count of Students Retention', 'Mean 1st Year Retention', 'Mean Total Earned Hours', 'Mean 1st Year GPA']\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5bb58bd7-f039-4df0-9e0a-f15cf37e5142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>College</th>\n",
       "      <th>Major 1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">CAS</th>\n",
       "      <th>American Studies</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Economics</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Religious Studies</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physics</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modern Languages</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">SEC</th>\n",
       "      <th>SOE Undeclared</th>\n",
       "      <td>0.966667</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biomedical Engineering</th>\n",
       "      <td>0.941176</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Computer Science</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAN</th>\n",
       "      <th>Nursing</th>\n",
       "      <td>0.935028</td>\n",
       "      <td>354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">CAS</th>\n",
       "      <th>Sports Media</th>\n",
       "      <td>0.933333</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Biology</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Chemistry</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSB</th>\n",
       "      <th>DSB Undeclared</th>\n",
       "      <td>0.923554</td>\n",
       "      <td>484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAS</th>\n",
       "      <th>Sociology and Anthropology</th>\n",
       "      <td>0.923077</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">DSB</th>\n",
       "      <th>Business Analytics</th>\n",
       "      <td>0.920000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finance</th>\n",
       "      <td>0.916667</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accounting</th>\n",
       "      <td>0.912500</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CAS</th>\n",
       "      <th>Undeclared</th>\n",
       "      <td>0.907473</td>\n",
       "      <td>281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Communication</th>\n",
       "      <td>0.904762</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEC</th>\n",
       "      <th>Mechanical Engineering</th>\n",
       "      <td>0.893617</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAS</th>\n",
       "      <th>History</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAN</th>\n",
       "      <th>Social Work</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSB</th>\n",
       "      <th>Management</th>\n",
       "      <td>0.881579</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAS</th>\n",
       "      <th>Psychology</th>\n",
       "      <td>0.878307</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EGAN</th>\n",
       "      <th>Public Health</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSB</th>\n",
       "      <th>Marketing</th>\n",
       "      <td>0.868750</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAS</th>\n",
       "      <th>Visual &amp; Performing Arts</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DSB</th>\n",
       "      <th>Economics</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAS</th>\n",
       "      <th>Mathematics</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SEC</th>\n",
       "      <th>Electrical and Computer Engineering</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">CAS</th>\n",
       "      <th>English</th>\n",
       "      <td>0.840000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Digital Journalism</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Politics</th>\n",
       "      <td>0.825000</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">DSB</th>\n",
       "      <th>Information Systems &amp; Ops Mgmt</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Business</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">CAS</th>\n",
       "      <th>Program on the Environment</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>International Studies</th>\n",
       "      <td>0.769231</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 mean  count\n",
       "College Major 1                                             \n",
       "CAS     American Studies                     1.000000      2\n",
       "        Economics                            1.000000      7\n",
       "        Religious Studies                    1.000000      1\n",
       "        Physics                              1.000000      5\n",
       "        Modern Languages                     1.000000      1\n",
       "SEC     SOE Undeclared                       0.966667     30\n",
       "        Biomedical Engineering               0.941176     17\n",
       "        Computer Science                     0.937500     48\n",
       "EGAN    Nursing                              0.935028    354\n",
       "CAS     Sports Media                         0.933333     15\n",
       "        Biology                              0.928571    140\n",
       "        Chemistry                            0.928571     28\n",
       "DSB     DSB Undeclared                       0.923554    484\n",
       "CAS     Sociology and Anthropology           0.923077     13\n",
       "DSB     Business Analytics                   0.920000     25\n",
       "        Finance                              0.916667    240\n",
       "        Accounting                           0.912500     80\n",
       "CAS     Undeclared                           0.907473    281\n",
       "        Communication                        0.904762     63\n",
       "SEC     Mechanical Engineering               0.893617     47\n",
       "CAS     History                              0.888889     27\n",
       "EGAN    Social Work                          0.888889      9\n",
       "DSB     Management                           0.881579     76\n",
       "CAS     Psychology                           0.878307    189\n",
       "EGAN    Public Health                        0.875000     16\n",
       "DSB     Marketing                            0.868750    160\n",
       "CAS     Visual & Performing Arts             0.857143     28\n",
       "DSB     Economics                            0.846154     26\n",
       "CAS     Mathematics                          0.846154     13\n",
       "SEC     Electrical and Computer Engineering  0.846154     13\n",
       "CAS     English                              0.840000     25\n",
       "        Digital Journalism                   0.833333      6\n",
       "        Politics                             0.825000     40\n",
       "DSB     Information Systems & Ops Mgmt       0.818182     11\n",
       "        International Business               0.818182     22\n",
       "CAS     Program on the Environment           0.800000     20\n",
       "        International Studies                0.769231     13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df.groupby(['College', 'Major 1'])['1st Year Retention'].agg(['mean', 'count']).sort_values(by='mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dfb9e7f-d05d-424d-8c16-05bec490c10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Group by College and Major 1, calculate mean retention and count, then sort\n",
    "grouped_data = student_df.groupby(['College', 'Major 1'])['1st Year Retention'].agg(['mean', 'count']).sort_values(by='mean', ascending=False).reset_index()\n",
    "\n",
    "# Plotting the scatter plot with switched axes\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=grouped_data, x='mean', y='count', hue='College', palette='viridis')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.title('Mean Retention Rate vs Count by College and Major 1')\n",
    "plt.xlabel('Mean Retention Rate')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Show plot\n",
    "plt.legend(title='College')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43721622-59f5-430f-a31f-5c6b65fd9c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjnUlEQVR4nO3deXhU9dn/8c8kmQwJJMiapcQQNUCVEBUswqMCYqKAuOD6aBXqRgURBItFqg4uiWJFLFTsgiwqhadaqCtNLARKwQoIGqlStQG3xChGAgSTIfn+/vCX0clGEmbOLOf9uq5cOmfOfOe+cyZw85mTMw5jjBEAAAAAAABgoahgFwAAAAAAAAD7IZQCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCJB04cEAzZ85Ubm6uevToIYfDIbfb3a61qqqq5Ha7VVRUdNR9H330UTkcDr344otN3n/++eera9eu+vzzz9tVi7+9/PLLuvjii5WamqrY2FglJCTotNNO03333aePP/7YZ9/hw4fL4XB4v+Li4pSdna358+errq6u0dqnn366HA6Hfv3rX7epph07dmjYsGHq3LmzHA6H5s+ffywtHtUPe3I4HEpMTNTQoUP1pz/9qd1r5uXlac2aNf4rsgWvvvpqs6/t3r17a8KECZbUEWgLFixQv3795HK5lJGRoTlz5sjj8QS7LACIeMxUrcNMxUwVDubPn69x48YpIyNDDodDw4cPD3ZJiEQGgCkpKTGdO3c255xzjrnpppuMJHPfffe1a60vv/yy1Y+vra01Z511lklOTjb79u3zue93v/udkWT+9Kc/tasOf6qtrTXXX3+9kWRGjRplli5daoqKisxrr71m7r//fpORkWF69erl85hhw4aZE044wWzZssVs2bLF/PWvfzWjRo0ykszMmTN99t2xY4eRZCSZfv36tam2U0891WRmZppXX33VbNmyxZSWlh5zvy2RZC6//HKzZcsWs3nzZvPcc8+ZU045xUgyzz33XLvW7Nixoxk/frx/C23G5MmTTXN/9L/11lvmww8/tKSOQHrwwQeNw+Ews2bNMuvXrzdz5841sbGx5uabbw52aQAQ8ZipWsZM9T1mqtDXt29fc/rpp5sbbrjB9OjRwwwbNizYJSECEUoBxpi6ujpTV1dnjGnbANSUtj7+o48+Mp06dTJXX321d9uePXtMQkKCueKKK9pVQ3tUVVU1e19eXp6RZPLz85u83+PxmIULF/psGzZsmDnllFN8ttXU1JgTTjjBxMfHm5qaGu/2+r/Ux4wZYySZf/7zn62uOyYmxtx6662t3v9oampqjMfjafZ+SWby5Mk+2/bs2WMkmXPOOaddzxkqA1Qk+Oqrr0yHDh3MLbfc4rP9oYceMg6Hw+zatStIlQGAPTBTMVP9sEZmqvBWW1vr/f9TTjmFUAoBEdk/RUA7HG0A+vvf/26GDRtmunbtajp06GDS0tLMuHHjzKFDh0xJSYn33akffh3tL8ennnrKSDLPP/+8qaurMyNHjjTJycnmq6++MsYYU1paam655Rbzox/9yDidTtO7d2/jdrsb/UXvdrvNT37yE9OlSxeTkJBgTjvtNPPHP/7ROxzWS09PN2PGjDEvvPCCOfXUU43L5TJ33XVXk7VVV1eb4447zvTv379138D/r6kByhhjrrjiCiPJfPbZZ8YYYw4fPmy6dOliBg4caP7zn/8YSebGG2886vpLlixp8ntdr7i42Fx00UXmuOOOMy6Xy2RnZ5ulS5f6rLF+/XojySxfvtxMnz7dpKamGofDYd57771mn7epAcoYY3r06GH69u3rs23//v1mxowZpnfv3sbpdJrU1FQzdepUc/DgQZ/1Gn798C/81hz7+tfdo48+ah577DHTu3dv07FjR3PmmWeaLVu2ePcbP358k89XUlJijPnuddHwtbp3715z7bXXmh49epjY2FjTr18/8+tf/9pnSGnt81vh2WefNZIaPe/nn39uJJmHHnrI0noAwM6YqXwxU/lipgrtmaohQikESkxrfsUPwHf27NmjMWPG6Oyzz9bTTz+t4447Tp999pnWrl2rmpoapaSkaO3atbrgggt044036qabbpIk9ejRo8V1J06cqDVr1ujWW2/Vv//9b/3973/XSy+9pG7duqmsrEw/+clPFBUVpXvvvVcnnniitmzZogcffFB79uzRkiVLfOqbOHGijj/+eEnSG2+8oSlTpuizzz7Tvffe6/Ocb731lt577z396le/UkZGhjp27Nhkbdu2bdM333yjW2+99Vi+dV4fffSRYmJi1KVLF0nSX/7yF1VUVOiGG25QZmamzjrrLK1atUrz589Xp06dml1nzJgx2rJli4YMGaLLL79cM2bM8N63e/duDR06VD179tRvfvMbdevWTc8++6wmTJigL774QjNnzvRZa9asWRoyZIieeuopRUVFqWfPnm3qaf/+/fr666915plnerdVVVVp2LBh+vTTT3X33XdrwIAB2rVrl+69914VFxfr9ddfl8Ph0JYtW3TuuedqxIgRuueeeyRJiYmJktSmYy9Jv/3tb9WvXz/vNSDuuecejR49WiUlJercubPuueceHTp0SM8//7y2bNnifVxKSkqTfX355ZcaOnSoampq9MADD6h37956+eWXdeedd+qjjz7Sk08+2abnb8mRI0eO/o2WFB0dLYfD0ez97777riQpKyvLZ3tKSoq6d+/uvR8AEFzMVMeOmYqZqin+mqkAywQ7FQNCTUvv6j3//PNGktm5c2e7Ht+Szz77zHTp0qXRu1oTJ040nTp1Mnv37vXZ/9e//rWR1OyvI9XW1hqPx2Puv/9+061bN5939tLT0010dLTZvXv3UetauXKlkWSeeuqpRvd5PB6frx+qf1ev/r7PP//c/PKXvzSSfE6hP/fcc02HDh1MRUWFMeb7d+sWL1581NqMafpdtquvvtq4XC7z8ccf+2wfNWqUiY+PN998840x5vt39dpyirgkM2nSJOPxeExNTY35z3/+Yy666CKTkJBgtm3b5t0vPz/fREVFma1bt/o8vv419Oqrr3q3NXeqeWuPff27allZWebIkSPe/d58881G19Bo6VTzhu/q1R+vf/3rXz773XrrrcbhcHhfP215/qY09254U1/r169vca2bb77ZuFyuJu/r06ePyc3NbfHxAAD/YabyxUzV+PmYqUJ3pmqIM6UQKHz6HtAGp556qmJjY3XLLbdo2bJl+u9//+u3tVNTUzVx4kRJ0v333+/d/vLLL2vEiBFKTU3VkSNHvF+jRo2SJG3YsMG777p163Teeeepc+fOio6OltPp1L333qt9+/apvLzc5/kGDBigPn36tLveb775Rk6n0+dr27ZtPvvs2rXLe19qaqoee+wxXXvttfrDH/4gSSopKdH69es1btw4HXfccZKkK664QgkJCXr66afbXdu6des0cuRIpaWl+WyfMGGCqqqqfN7RkqTLLrusTes/+eSTcjqdio2NVZ8+ffTaa6/pT3/6kwYOHOjd5+WXX1b//v116qmn+hy3888/Xw6Ho1WfJNSWYy99905ndHS09/aAAQMkSXv37m1Tf/XWrVunk08+WT/5yU98tk+YMEHGGK1bt84vz5+amqqtW7e26uuH3+PmtPSuH+8IAkBoYKb6HjMVM1WozlSAFfj1PaANTjzxRL3++uuaO3euJk+erEOHDumEE07Q7bffrqlTpx7z+i6XS5IUGxvr3fbFF1/opZdektPpbPIxX331lSTpzTffVG5uroYPH64//OEP6tWrl2JjY7VmzRo99NBDOnz4sM/jmju9uKH609Yb/iWYkJCgrVu3SvruL/o5c+Y0euyJJ56olStXyuFwqEOHDsrIyFB8fLz3/qefflrGGF1++eX65ptvvNsvuugiPffcc3r//ffVr1+/VtX5Q/v27Wuyv9TUVO/9P9Ta70W9K6+8Ur/4xS/k8XhUXFysWbNm6eqrr9Zbb72lzMxMSd8dtw8//PCox60lrT329bp16+Zzu/711PDYt9a+ffvUu3fvRtub+z629/ljY2N16qmntqqmHw5oTenWrZu+/fZbVVVV+bzWJOnrr79mAAOAEMFM9T1mKmaqUJypAKsQSgFtdPbZZ+vss89WbW2ttm3bpgULFmjatGlKSkrS1Vdf7ffn6969uwYMGKCHHnqoyfvr/zJbuXKlnE6nXn75ZXXo0MF7/5o1a5p8XGvPGBk4cKC6dOmil156SXl5ed7t0dHRGjRokCQ1e52eDh06ePdpqK6uTkuXLpUkjRs3rsl9nn76ac2dO7dVdf5Qt27dVFpa2mj7559/Lum77+kPtfXsmR49enj7GjJkiH784x9r2LBhuuOOO/Tyyy97nyMuLq7Zdycb1tDcPq059oHS1u9je+3Zs0cZGRmt2nf9+vUaPnx4s/fXX0uquLhYgwcP9m4vKyvTV199pf79+x9TrQAA/2Gm+g4zFTNVKM5UgFUIpYB2io6O1uDBg9WvXz8999xzeuutt3T11Vcf8zspDV144YV69dVXdeKJJ3ovZNkUh8OhmJgYn3c9Dh8+rGeeeeaYnj82Nla/+MUvdPfdd+uRRx7RXXfddUzr1fvb3/6mTz/9VJMnT9bll1/e6P7bbrtNy5cvV15enmJi2vZH1ciRI7V69Wp9/vnnPkPG8uXLFR8f73PxTH84++yzdf3112vZsmXeC4VeeOGFysvLU7du3Y46HLhcriZfL6099m3xw9dnXFxci/uOHDlS+fn5euutt3T66ad7ty9fvlwOh0MjRozwS031p5q3Rt++fVu8/4ILLlCHDh20dOlSn1Bq6dKlcjgcuuSSS46lVABAADBTHRtmqu8xU/lvpgKsQigF/H+vvfaaDh06pAMHDkiS/v3vf+v555+XJI0ePVrx8fF66qmntG7dOo0ZM0bHH3+8vv32W++7Nuedd56k707BTk9P11//+leNHDlSXbt2Vffu3Zs8Zbc17r//fhUWFmro0KG6/fbb1bdvX3377bfas2ePXn31VT311FPq1auXxowZo3nz5umaa67RLbfcon379unXv/619y/MY3HXXXfp/fff1y9/+Utt3LhRV111lXr37q3q6mr997//1R//+EdFR0c3+nWplixevFgxMTG6++67m3x3auLEibr99tv1yiuv6OKLL25Tvffdd5/32gH33nuvunbtqueee06vvPKK5s6de9RPLWmPBx54QKtWrdI999yj119/XdOmTdMLL7ygc845R3fccYcGDBiguro6ffzxxyooKNCMGTO8oUlWVpaKior00ksvKSUlRQkJCerbt2+rj31b1J9J9Mgjj2jUqFGKjo7WgAEDfH69od4dd9yh5cuXa8yYMbr//vuVnp6uV155RU8++aRuvfXWY7p+xg/FxsY2++5vW3Xt2lW/+tWvdM8996hr167Kzc3V1q1b5Xa7ddNNN+nkk0/2y/MAAJrHTNU8ZqqjY6ZqP3/OVNJ3nxi5Z88eSVJlZaWMMd6f5TPOOEPp6el+ey7YWFAvsw6EkPT09GY/naKkpMQYY8yWLVvMpZdeatLT043L5TLdunUzw4YNMy+++KLPWq+//ro57bTTjMvlMpKa/BSQptx3331Gkvnyyy99tn/55Zfm9ttvNxkZGcbpdJquXbuagQMHmtmzZ5uDBw9693v66adN3759jcvlMieccILJz883ixcv9umhvtcxY8a0+Xv04osvmrFjx5qkpCQTExNjEhISzKmnnmpmzJhh3n//fZ996z8ppilffvmliY2NNZdcckmzz1VRUWHi4uLM2LFjW6xJTXxSjDHGFBcXm7Fjx5rOnTub2NhYk52dbZYsWeKzT/0nxfz5z39u8Tla83zGGPOLX/zCSDIbNmwwxhhz8OBB86tf/cr07dvXxMbGms6dO5usrCxzxx13mLKyMu/jdu7caf7nf/7HxMfHG0k+n2zSmmNf/0krjz76aJP1/vBTi6qrq81NN91kevToYRwOh89ro+EnxRhjzN69e80111xjunXrZpxOp+nbt6959NFHTW1trXeftjy/VZ544gnTp08fExsba44//nhz3333mZqaGsvrAAA7YqY6OmYqZqpwmKnGjx/f7M9yw9cA0F4OY4wJTNwFAAAAAAAANC0q2AUAAAAAAADAfgilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYLmYYBcQaHV1dfr888+VkJAgh8MR7HIAAEAIM8bowIEDSk1NVVQU7939EDMVAABordbOVBEfSn3++edKS0sLdhkAACCMfPLJJ+rVq1ewywgpzFQAAKCtjjZTRXwolZCQIOm7b0RiYqLf1/d4PCooKFBubq6cTqff1w81durXTr1K9Bvp6Ddy2alXKfD9VlZWKi0tzTs/4HuBnqmCzW4/Sw3ZuX879y7RP/3bt3879y6FzkwV8aFU/enliYmJAQul4uPjlZiYaIsXsp36tVOvEv1GOvqNXHbqVbKuX349rbFAz1TBZrefpYbs3L+de5fon/7t27+de5dCZ6biYgkAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwXMiEUvn5+XI4HJo2bZp3mzFGbrdbqampiouL0/Dhw7Vr167gFQkAAAAAAAC/CIlQauvWrfr973+vAQMG+GyfO3eu5s2bp4ULF2rr1q1KTk5WTk6ODhw4EKRKAQAAAAAA4A9BD6UOHjyoa6+9Vn/4wx/UpUsX73ZjjObPn6/Zs2dr3Lhx6t+/v5YtW6aqqiqtWLEiiBUDAAAAAADgWMUEu4DJkydrzJgxOu+88/Tggw96t5eUlKisrEy5ubnebS6XS8OGDdPmzZs1ceLEJterrq5WdXW193ZlZaUkyePxyOPx+L3++jUDsXYoslO/dupVot9IR7+Ry069SoHv1y7fRwAAgFAQ1FBq5cqVeuutt7R169ZG95WVlUmSkpKSfLYnJSVp7969za6Zn5+vOXPmNNpeUFCg+Pj4Y6y4eYWFhQFbOxTZqV879SrRb6Sj38hlp16lwPVbVVUVkHUBAADayl3kDtjaUSZK2coO2PqtFbRQ6pNPPtHUqVNVUFCgDh06NLufw+HwuW2MabTth2bNmqXp06d7b1dWViotLU25ublKTEw89sIb8Hg8KiwsVE5OjpxOp9/XDzV26tdOvUr0G+noN3K1p9f8/MDWNGtW4NYO9LGtP8MaAAAAgRe0UGr79u0qLy/XwIEDvdtqa2u1ceNGLVy4ULt375b03RlTKSkp3n3Ky8sbnT31Qy6XSy6Xq9F2p9MZ0H+YBHr9UGOnfu3Uq0S/kY5+I1dbeq2rC3QtgV3/u+cIzLG1y+sFAAAgFATtQucjR45UcXGxdu7c6f0aNGiQrr32Wu3cuVMnnHCCkpOTfU7Pr6mp0YYNGzR06NBglQ0AAAAAAAA/CNqZUgkJCerfv7/Pto4dO6pbt27e7dOmTVNeXp4yMzOVmZmpvLw8xcfH65prrglGyQAAAAAAAPCToH/6Xktmzpypw4cPa9KkSaqoqNDgwYNVUFCghISEYJcGAAAAAACAYxBSoVRRUZHPbYfDIbfbLbfbHZR6AAAAAAAAEBhBu6YUAAAAAAAA7ItQCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWC4m2AUAAAAAAACEG3eRO9glhD3OlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJaLCXYBAAAAAAAA/uYucjd7X5SJUraylb8pX3WOOuuKgg/OlAIAAAAAAIDlCKUAAAAAAABguaCGUosWLdKAAQOUmJioxMREDRkyRK+99pr3/gkTJsjhcPh8nXnmmUGsGAAAAAAAAP4Q1GtK9erVSw8//LBOOukkSdKyZct08cUXa8eOHTrllFMkSRdccIGWLFnifUxsbGxQagUAAAAAAID/BDWUGjt2rM/thx56SIsWLdIbb7zhDaVcLpeSk5ODUR4AAAAAAAACJGSuKVVbW6uVK1fq0KFDGjJkiHd7UVGRevbsqT59+ujmm29WeXl5EKsEAAAInvz8fDkcDk2bNs27zRgjt9ut1NRUxcXFafjw4dq1a5fP46qrqzVlyhR1795dHTt21EUXXaRPP/3U4uoBAAB8BfVMKUkqLi7WkCFD9O2336pTp05avXq1Tj75ZEnSqFGjdMUVVyg9PV0lJSW65557dO6552r79u1yuVxNrlddXa3q6mrv7crKSkmSx+ORx+Pxe/31awZi7VBkp37t1KtEv5GOfiNXe3qNCvBbUoH8tgf62Ibya2br1q36/e9/rwEDBvhsnzt3rubNm6elS5eqT58+evDBB5WTk6Pdu3crISFBkjRt2jS99NJLWrlypbp166YZM2bowgsv1Pbt2xUdHR2MdgAAAIIfSvXt21c7d+7UN998oxdeeEHjx4/Xhg0bdPLJJ+uqq67y7te/f38NGjRI6enpeuWVVzRu3Lgm18vPz9ecOXMabS8oKFB8fHzA+igsLAzY2qHITv3aqVeJfiMd/UautvSanR3AQiS9+mpg15cCd2yrqqoCsu6xOnjwoK699lr94Q9/0IMPPujdbozR/PnzNXv2bO9stGzZMiUlJWnFihWaOHGi9u/fr8WLF+uZZ57ReeedJ0l69tlnlZaWptdff13nn39+UHoCAAAIeigVGxvrvdD5oEGDtHXrVj3xxBP63e9+12jflJQUpaen64MPPmh2vVmzZmn69One25WVlUpLS1Nubq4SExP9Xr/H41FhYaFycnLkdDr9vn6osVO/dupVot9IR7+Rqz295ucHtqZZswK3dqCPbf0Z1qFm8uTJGjNmjM477zyfUKqkpERlZWXKzc31bnO5XBo2bJg2b96siRMnavv27fJ4PD77pKamqn///tq8eXOzoZTVZ58Hm53OsGyKnfu3c+8S/dN/ZPcfZZo/Pbz+vpb2iWT1fQf77POgh1INGWN8BqAf2rdvnz755BOlpKQ0+3iXy9Xkr/Y5nc6A/sMk0OuHGjv1a6deJfqNdPQbudrSa11doGsJ7PrfPUdgjm0ovl5Wrlypt956S1u3bm10X1lZmSQpKSnJZ3tSUpL27t3r3Sc2NlZdunRptE/945sSrLPPg81OZ1g2xc7927l3if7pPzL7z9bRTw/POpBlQSWhK9hnnwc1lLr77rs1atQopaWl6cCBA1q5cqWKioq0du1aHTx4UG63W5dddplSUlK0Z88e3X333erevbsuvfTSYJYNAABgiU8++URTp05VQUGBOnTo0Ox+DofD57YxptG2ho62j9Vnnwebnc6wbIqd+7dz7xL9039k95+/qfnTw6NMlLIOZKk4oVh1jgC/YxeC6vsP9tnnQQ2lvvjiC1133XUqLS1V586dNWDAAK1du1Y5OTk6fPiwiouLtXz5cn3zzTdKSUnRiBEjtGrVKu9FOwEAACLZ9u3bVV5eroEDB3q31dbWauPGjVq4cKF2794t6buzoX54Jnl5ebn37Knk5GTV1NSooqLC52yp8vJyDR06tNnnDtbZ58EW6f0djZ37t3PvEv3Tf2T235qwqc5RZ8tQql6wzz4Paii1ePHiZu+Li4vT3/72NwurAQAACC0jR45UcXGxz7af/exn6tevn+666y6dcMIJSk5OVmFhoU477TRJUk1NjTZs2KBHHnlEkjRw4EA5nU4VFhbqyiuvlCSVlpbq3Xff1dy5c61tCAAA4AdC7ppSAAAA+E5CQoL69+/vs61jx47q1q2bd/u0adOUl5enzMxMZWZmKi8vT/Hx8brmmmskSZ07d9aNN96oGTNmqFu3buratavuvPNOZWVleT+NDwAAIBgIpQAAAMLYzJkzdfjwYU2aNEkVFRUaPHiwCgoKfC538PjjjysmJkZXXnmlDh8+rJEjR2rp0qWKjo4OYuUAAMDuCKUAAADCSFFRkc9th8Mht9stt9vd7GM6dOigBQsWaMGCBYEtDgAAoA2igl0AAAAAAAAA7IdQCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlghpKLVq0SAMGDFBiYqISExM1ZMgQvfbaa977jTFyu91KTU1VXFychg8frl27dgWxYgAAAAAAAPhDUEOpXr166eGHH9a2bdu0bds2nXvuubr44ou9wdPcuXM1b948LVy4UFu3blVycrJycnJ04MCBYJYNAAAAAACAYxTUUGrs2LEaPXq0+vTpoz59+uihhx5Sp06d9MYbb8gYo/nz52v27NkaN26c+vfvr2XLlqmqqkorVqwIZtkAAAAAAAA4RjHBLqBebW2t/vznP+vQoUMaMmSISkpKVFZWptzcXO8+LpdLw4YN0+bNmzVx4sQm16murlZ1dbX3dmVlpSTJ4/HI4/H4ve76NQOxdiiyU7926lWi30hHv5GrPb1GBfgtqUB+2wN9bO3wmgEAAAgVQQ+liouLNWTIEH377bfq1KmTVq9erZNPPlmbN2+WJCUlJfnsn5SUpL179za7Xn5+vubMmdNoe0FBgeLj4/1b/A8UFhYGbO1QZKd+7dSrRL+Rjn4jV1t6zc4OYCGSXn01sOtLgTu2VVVVAVkXAAAAjQU9lOrbt6927typb775Ri+88ILGjx+vDRs2eO93OBw++xtjGm37oVmzZmn69One25WVlUpLS1Nubq4SExP9Xr/H41FhYaFycnLkdDr9vn6osVO/dupVot9IR7+Rqz295ucHtqZZswK3dqCPbf0Z1gAAAAi8oIdSsbGxOumkkyRJgwYN0tatW/XEE0/orrvukiSVlZUpJSXFu395eXmjs6d+yOVyyeVyNdrudDoD+g+TQK8fauzUr516leg30tFv5GpLr3V1ga4lsOt/9xyBObZ2eb0AAACEgqBe6LwpxhhVV1crIyNDycnJPqfn19TUaMOGDRo6dGgQKwQAAAAAAMCxCuqZUnfffbdGjRqltLQ0HThwQCtXrlRRUZHWrl0rh8OhadOmKS8vT5mZmcrMzFReXp7i4+N1zTXXBLNsAAAAAAAAHKOghlJffPGFrrvuOpWWlqpz584aMGCA1q5dq5ycHEnSzJkzdfjwYU2aNEkVFRUaPHiwCgoKlJCQEMyyAQAAAAAAcIyCGkotXry4xfsdDofcbrfcbrc1BQEAAAAAAMASIXdNKQAAAAAAAEQ+QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGC5oH76HgAAiDyB/NDcqCgpOztw6wMAAMA6nCkFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALBcTLALAAAgHLnd4bk2AAAAECo4UwoAAAAAAACWI5QCAAAAAACA5fj1PQAAAAAAYDl3kTvYJSDIOFMKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAIAQtmjRIg0YMECJiYlKTEzUkCFD9Nprr3nvN8bI7XYrNTVVcXFxGj58uHbt2uWzRnV1taZMmaLu3burY8eOuuiii/Tpp59a3QoAAIAPQikAAIAQ1qtXLz388MPatm2btm3bpnPPPVcXX3yxN3iaO3eu5s2bp4ULF2rr1q1KTk5WTk6ODhw44F1j2rRpWr16tVauXKlNmzbp4MGDuvDCC1VbWxustgAAAAilAAAAQtnYsWM1evRo9enTR3369NFDDz2kTp066Y033pAxRvPnz9fs2bM1btw49e/fX8uWLVNVVZVWrFghSdq/f78WL16sxx57TOedd55OO+00PfvssyouLtbrr78e5O4AAICdxQS7AAAAALRObW2t/vznP+vQoUMaMmSISkpKVFZWptzcXO8+LpdLw4YN0+bNmzVx4kRt375dHo/HZ5/U1FT1799fmzdv1vnnn9/kc1VXV6u6utp7u7KyUpLk8Xjk8XgC1GHw1PcUib21hp37t3PvEv3Tf3D7jzLBO0+m/rmDWUMw1fcdqGPf2nUJpQAAAEJccXGxhgwZom+//VadOnXS6tWrdfLJJ2vz5s2SpKSkJJ/9k5KStHfvXklSWVmZYmNj1aVLl0b7lJWVNfuc+fn5mjNnTqPtBQUFio+PP9aWQlZhYWGwSwgqO/dv594l+qf/4PSfreygPO8PZR3ICnYJQRWoY19VVdWq/QilAAAAQlzfvn21c+dOffPNN3rhhRc0fvx4bdiwwXu/w+Hw2d8Y02hbQ0fbZ9asWZo+fbr3dmVlpdLS0pSbm6vExMR2dhK6PB6PCgsLlZOTI6fTGexyLGfn/u3cu0T/9B/c/vM35Vv+nPWiTJSyDmSpOKFYdY66oNURLPX9B+rY159hfTSEUgAAACEuNjZWJ510kiRp0KBB2rp1q5544gndddddkr47GyolJcW7f3l5uffsqeTkZNXU1KiiosLnbKny8nINHTq02ed0uVxyuVyNtjudzoj+h1uk93c0du7fzr1L9E//wek/FMKgOkddSNQRLIE69q1d056/PAkAABDGjDGqrq5WRkaGkpOTfU69r6mp0YYNG7yB08CBA+V0On32KS0t1bvvvttiKAUAABBonCkFAAAQwu6++26NGjVKaWlpOnDggFauXKmioiKtXbtWDodD06ZNU15enjIzM5WZmam8vDzFx8frmmuukSR17txZN954o2bMmKFu3bqpa9euuvPOO5WVlaXzzjsvyN0BAAA7I5QCAAAIYV988YWuu+46lZaWqnPnzhowYIDWrl2rnJwcSdLMmTN1+PBhTZo0SRUVFRo8eLAKCgqUkJDgXePxxx9XTEyMrrzySh0+fFgjR47U0qVLFR0dHay2AAAACKUAAABC2eLFi1u83+FwyO12y+12N7tPhw4dtGDBAi1YsMDP1QEAALQf15QCAAAAAACA5QilAAAAAAAAYLmghlL5+fk644wzlJCQoJ49e+qSSy7R7t27ffaZMGGCHA6Hz9eZZ54ZpIoBAAAAAADgD0ENpTZs2KDJkyfrjTfeUGFhoY4cOaLc3FwdOnTIZ78LLrhApaWl3q9XX301SBUDAAAAAADAH4J6ofO1a9f63F6yZIl69uyp7du365xzzvFud7lcSk5Otro8AAAAAAAABEhIffre/v37JUldu3b12V5UVKSePXvquOOO07Bhw/TQQw+pZ8+eTa5RXV2t6upq7+3KykpJksfjkcfj8XvN9WsGYu1QZKd+7dSrRL+Rjn79LyqA5xq3pez29BrI2gMtKiqwx9YuPyMAAAChIGRCKWOMpk+frrPOOkv9+/f3bh81apSuuOIKpaenq6SkRPfcc4/OPfdcbd++XS6Xq9E6+fn5mjNnTqPtBQUFio+PD1j9hYWFAVs7FNmpXzv1KtFvpKNf/8nODtjSas9vqbel10DWbpVAHduqqqqArAsAAIDGQiaUuu222/TOO+9o06ZNPtuvuuoq7//3799fgwYNUnp6ul555RWNGzeu0TqzZs3S9OnTvbcrKyuVlpam3NxcJSYm+r1uj8ejwsJC5eTkyOl0+n39UGOnfu3Uq0S/kY5+/S8/PyDLSpJmzWr9vu3pNZC1B1pUlEdZWYE7tvVnWAMAACDwQiKUmjJlil588UVt3LhRvXr1anHflJQUpaen64MPPmjyfpfL1eQZVE6nM6D/EAv0+qHGTv3aqVeJfiMd/fpPXV1AlpUktafktvQayNqtEqhja6efDwAAgGALaihljNGUKVO0evVqFRUVKSMj46iP2bdvnz755BOlpKRYUCEAAAAAAAACIaiXOp08ebKeffZZrVixQgkJCSorK1NZWZkOHz4sSTp48KDuvPNObdmyRXv27FFRUZHGjh2r7t2769JLLw1m6QAAAAAAADgGQT1TatGiRZKk4cOH+2xfsmSJJkyYoOjoaBUXF2v58uX65ptvlJKSohEjRmjVqlVKSEgIQsUAAAAAAADwh6D/+l5L4uLi9Le//c2iagAAAAAAAGCVoP76HgAAAAAAAOyJUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFguqJ++BwAAGnO7W79vVJSUnS3l50t1dQErCQAAAPA7zpQCAAAAAACA5QilAAAAAAAAYLl2hVIlJSX+rgMAACCiMC8BAAC0rF2h1EknnaQRI0bo2Wef1bfffuvvmgAAAMIe8xIAAEDL2hVKvf322zrttNM0Y8YMJScna+LEiXrzzTf9XRsAAEDYYl4CAABoWbtCqf79+2vevHn67LPPtGTJEpWVlemss87SKaeconnz5unLL7/0d50AAABhhXkJAACgZcd0ofOYmBhdeuml+r//+z898sgj+uijj3TnnXeqV69euv7661VaWuqvOgEAAMIS8xIAAEDTjimU2rZtmyZNmqSUlBTNmzdPd955pz766COtW7dOn332mS6++GJ/1QkAABCWmJcAAACaFtOeB82bN09LlizR7t27NXr0aC1fvlyjR49WVNR3GVdGRoZ+97vfqV+/fn4tFgAAIFwwLwEAALSsXaHUokWLdMMNN+hnP/uZkpOTm9zn+OOP1+LFi4+pOAAAgHDFvAQAANCydoVSH3zwwVH3iY2N1fjx49uzPAAAQNhjXgIAAGhZu0KpJUuWqFOnTrriiit8tv/5z39WVVUVwxUAICTk50t1dcGuAnbFvAQAANCydl3o/OGHH1b37t0bbe/Zs6fy8vKOuSgAAIBwx7wEAADQsnaFUnv37lVGRkaj7enp6fr444+PuSgAAIBwx7wEAADQsnaFUj179tQ777zTaPvbb7+tbt26HXNRAAAA4Y55CQAAoGXtCqWuvvpq3X777Vq/fr1qa2tVW1urdevWaerUqbr66qv9XSMAAEDYYV4CAABoWbsudP7ggw9q7969GjlypGJivluirq5O119/PddIAAAAEPMSAADA0bQrlIqNjdWqVav0wAMP6O2331ZcXJyysrKUnp7u7/oAAADCEvMSAABAy9oVStXr06eP+vTp469aAAAAIg7zEgAAQNPaFUrV1tZq6dKl+vvf/67y8nLV1dX53L9u3Tq/FAcAABCumJcAAABa1q5QaurUqVq6dKnGjBmj/v37y+Fw+LsuAACAsMa8BAAA0LJ2hVIrV67U//3f/2n06NH+rgcAACAiMC8BAAC0LKo9D4qNjdVJJ53k71oAAAAiBvMSAABAy9oVSs2YMUNPPPGEjDH+rgcAACAiMC8BAAC0rF2/vrdp0yatX79er732mk455RQ5nU6f+//yl7/4pTgAAIBwxbwEAADQsnaFUscdd5wuvfRSf9cCAAAQMZiXAAAAWtauUGrJkiX+rgMAACCiMC8BAAC0rF3XlJKkI0eO6PXXX9fvfvc7HThwQJL0+eef6+DBg34rDgAAIJwxLwEAADSvXWdK7d27VxdccIE+/vhjVVdXKycnRwkJCZo7d66+/fZbPfXUU/6uEwAAIKwwLwEAALSsXWdKTZ06VYMGDVJFRYXi4uK82y+99FL9/e9/91txAAAA4Yp5CQAAoGXt/vS9f/7zn4qNjfXZnp6ers8++8wvhQEAAIQz5iUAAICWtetMqbq6OtXW1jba/umnnyohIeGYiwIAAAh3zEsAAAAta1colZOTo/nz53tvOxwOHTx4UPfdd59Gjx7tr9oAAADCFvMSAABAy9r163uPP/64RowYoZNPPlnffvutrrnmGn3wwQfq3r27/vSnP/m7RgAAgLDDvAQAANCydoVSqamp2rlzp/70pz/prbfeUl1dnW688UZde+21PhfyBAAAsCvmJQAAgJa1K5SSpLi4ON1www264YYb/FkPAABAxGBeAgAAaF67Qqnly5e3eP/111/frmIAAAAiBfMSAABAy9oVSk2dOtXntsfjUVVVlWJjYxUfH8+QBQAAbI95CQAAoGXt+vS9iooKn6+DBw9q9+7dOuuss7hwJwAAgJiXAAAAjqZdoVRTMjMz9fDDDzd6VxAAAADfYV4CAAD4nt9CKUmKjo7W559/7s8lAQAAIgrzEgAAwHfadU2pF1980ee2MUalpaVauHCh/ud//scvhQEAAIQz5iUAAICWtSuUuuSSS3xuOxwO9ejRQ+eee64ee+wxf9QFAAAQ1piXAAAAWtauX9+rq6vz+aqtrVVZWZlWrFihlJSUVq+Tn5+vM844QwkJCerZs6cuueQS7d6922cfY4zcbrdSU1MVFxen4cOHa9euXe0pGwAAwDL+mpcAAAAilV+vKdVWGzZs0OTJk/XGG2+osLBQR44cUW5urg4dOuTdZ+7cuZo3b54WLlyorVu3Kjk5WTk5OTpw4EAQKwcAAAAAAMCxaNev702fPr3V+86bN6/Z+9auXetze8mSJerZs6e2b9+uc845R8YYzZ8/X7Nnz9a4ceMkScuWLVNSUpJWrFihiRMntqd8AACAgPPXvAQAABCp2hVK7dixQ2+99ZaOHDmivn37SpL+85//KDo6Wqeffrp3P4fD0aZ19+/fL0nq2rWrJKmkpERlZWXKzc317uNyuTRs2DBt3ryZUAoAAISsQM1LAAAAkaJdodTYsWOVkJCgZcuWqUuXLpKkiooK/exnP9PZZ5+tGTNmtHlNY4ymT5+us846S/3795cklZWVSZKSkpJ89k1KStLevXubXKe6ulrV1dXe25WVlZIkj8cjj8fT5rqOpn7NQKwdiuzUr516leg30tm136ioyO+3vkc79Cp932egXsv+XDcQ8xIAAEAkaVco9dhjj6mgoMA7YElSly5d9OCDDyo3N7ddQ9Ztt92md955R5s2bWp0X8N3EI0xzb6rmJ+frzlz5jTaXlBQoPj4+DbX1VqFhYUBWzsU2alfO/Uq0W+ks1u/WVn26ddOvUqBey1XVVX5ba1AzEsAAFjNXeQOdgmIYO0KpSorK/XFF1/olFNO8dleXl7erguQT5kyRS+++KI2btyoXr16ebcnJydL+u6MqR9+Sk15eXmjs6fqzZo1y+caDpWVlUpLS1Nubq4SExPbXNvReDweFRYWKicnR06n0+/rhxo79WunXiX6jXR27be4OEd1dZHdb1SUR1lZ9uhV+r7fQL2W68+w9tda/pyXAAAAIk27QqlLL71UP/vZz/TYY4/pzDPPlCS98cYb+sUvfuG9IHlrGGM0ZcoUrV69WkVFRcrIyPC5PyMjQ8nJySosLNRpp50mSaqpqdGGDRv0yCOPNLmmy+WSy+VqtN3pdAb0H2KBXj/U2KlfO/Uq0W+ks1u/dXVOWwQ1kr16lQL3Wvbnmv6alwAAACJVu0Kpp556Snfeead++tOfeq+9EBMToxtvvFGPPvpoq9eZPHmyVqxYob/+9a9KSEjwXkOqc+fOiouLk8Ph0LRp05SXl6fMzExlZmYqLy9P8fHxuuaaa9pTOgAAgCX8NS8BAABEqnaFUvHx8XryySf16KOP6qOPPpIxRieddJI6duzYpnUWLVokSRo+fLjP9iVLlmjChAmSpJkzZ+rw4cOaNGmSKioqNHjwYBUUFCghIaE9pQMAAFjCX/MSAABApGpXKFWvtLRUpaWlOueccxQXF9fiBcibYow56j4Oh0Nut1tut/sYKgUAAAiOY52XAAAAIlVUex60b98+jRw5Un369NHo0aNVWloqSbrpppv4JBkAAAAxLwEAABxNu0KpO+64Q06nUx9//LHi4+O926+66iqtXbvWb8UBAACEK+YlAACAlrXr1/cKCgr0t7/9Tb169fLZnpmZqb179/qlMAAAgHDGvAQAANCydp0pdejQIZ93/Op99dVXcrlcx1wUAABAuGNeAgAAaFm7QqlzzjlHy5cv9952OByqq6vTo48+qhEjRvitOAAAgHDFvAQAANCydv363qOPPqrhw4dr27Ztqqmp0cyZM7Vr1y59/fXX+uc//+nvGgEAAMIO8xIAAEDL2hVKnXzyyXrnnXe0aNEiRUdH69ChQxo3bpwmT56slJQUf9cIAIhAbnfg1o6KkrKzA7c+0BrMSwAAAC1rcyjl8XiUm5ur3/3ud5ozZ04gagIAAAhrzEsAAABH1+ZrSjmdTr377rtyOByBqAcAACDsMS8BAAAcXbsudH799ddr8eLF/q4FAAAgYjAvAQAAtKxd15SqqanRH//4RxUWFmrQoEHq2LGjz/3z5s3zS3EAAADhinkJAACgZW0Kpf773/+qd+/eevfdd3X66adLkv7zn//47MNp6gAAwM6YlwAAAFqnTaFUZmamSktLtX79eknSVVddpd/85jdKSkoKSHEAAADhhnkJAACgddp0TSljjM/t1157TYcOHfJrQQAAAOGMeQkAAKB12nWh83oNhy4AAAD4Yl4CAABoWptCKYfD0egaCFwTAQAA4HvMSwAAAK3TpmtKGWM0YcIEuVwuSdK3336rn//8540+TeYvf/mL/yoEAAAII8xLAAAArdOmUGr8+PE+t3/605/6tRgAAIBwx7wEAADQOm0KpZYsWRKoOgAAACIC8xIAAEDrHNOFzgEAAAAAAID2IJQCAAAAAACA5QilAAAAQlh+fr7OOOMMJSQkqGfPnrrkkku0e/dun32MMXK73UpNTVVcXJyGDx+uXbt2+exTXV2tKVOmqHv37urYsaMuuugiffrpp1a2AgAA4INQCgAAIIRt2LBBkydP1htvvKHCwkIdOXJEubm5OnTokHefuXPnat68eVq4cKG2bt2q5ORk5eTk6MCBA959pk2bptWrV2vlypXatGmTDh48qAsvvFC1tbXBaAsAAKBtFzoHAACAtdauXetze8mSJerZs6e2b9+uc845R8YYzZ8/X7Nnz9a4ceMkScuWLVNSUpJWrFihiRMnav/+/Vq8eLGeeeYZnXfeeZKkZ599VmlpaXr99dd1/vnnW94XAAAAoRQAAEAY2b9/vySpa9eukqSSkhKVlZUpNzfXu4/L5dKwYcO0efNmTZw4Udu3b5fH4/HZJzU1Vf3799fmzZubDKWqq6tVXV3tvV1ZWSlJ8ng88ng8AektmOp7isTeWsPO/du5d4n+6f/o/UeZyPwFq/q+IrW/o6nvO1Cv/dauSygFAAAQJowxmj59us466yz1799fklRWViZJSkpK8tk3KSlJe/fu9e4TGxurLl26NNqn/vEN5efna86cOY22FxQUKD4+/ph7CVWFhYXBLiGo7Ny/nXuX6J/+m+8/W9kWVmK9rANZwS4hqAL12q+qqmrVfoRSAAAAYeK2227TO++8o02bNjW6z+Fw+Nw2xjTa1lBL+8yaNUvTp0/33q6srFRaWppyc3OVmJjYjupDm8fjUWFhoXJycuR0OoNdjuXs3L+de5fon/6P3n/+pnyLq7JGlIlS1oEsFScUq85RF+xyLFfff6Be+/VnWB8NoRQAAEAYmDJlil588UVt3LhRvXr18m5PTk6W9N3ZUCkpKd7t5eXl3rOnkpOTVVNTo4qKCp+zpcrLyzV06NAmn8/lcsnlcjXa7nQ6I/ofbpHe39HYuX879y7RP/0333+kBzZ1jrqI77ElgXrtt3ZNe/7yJAAAQJgwxui2227TX/7yF61bt04ZGRk+92dkZCg5Odnn9Puamhpt2LDBGzgNHDhQTqfTZ5/S0lK9++67zYZSAAAAgcaZUgAAACFs8uTJWrFihf76178qISHBew2ozp07Ky4uTg6HQ9OmTVNeXp4yMzOVmZmpvLw8xcfH65prrvHue+ONN2rGjBnq1q2bunbtqjvvvFNZWVneT+MDAACwGqEUAABACFu0aJEkafjw4T7blyxZogkTJkiSZs6cqcOHD2vSpEmqqKjQ4MGDVVBQoISEBO/+jz/+uGJiYnTllVfq8OHDGjlypJYuXaro6GirWgEAAPBBKAUAABDCjDFH3cfhcMjtdsvtdje7T4cOHbRgwQItWLDAj9UBAAC0H9eUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYLibYBQAAAAAAgPZxF7nb/dgoE6VsZSt/U77qHHX+KwpoJc6UAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOWCGkpt3LhRY8eOVWpqqhwOh9asWeNz/4QJE+RwOHy+zjzzzOAUCwAAAAAAAL8Jaih16NAhZWdna+HChc3uc8EFF6i0tNT79eqrr1pYIQAAAAAAAAIhJphPPmrUKI0aNarFfVwul5KTky2qCAAAAAAAAFYI+WtKFRUVqWfPnurTp49uvvlmlZeXB7skAAAAAAAAHKOgnil1NKNGjdIVV1yh9PR0lZSU6J577tG5556r7du3y+VyNfmY6upqVVdXe29XVlZKkjwejzwej99rrF8zEGuHIjv1a6deJfqNdKHYb1QA3xaJivL4/DeS2alX6fs+A/VaDqWfEQAAgEgX0qHUVVdd5f3//v37a9CgQUpPT9crr7yicePGNfmY/Px8zZkzp9H2goICxcfHB6zWwsLCgK0diuzUr516leg30oVSv9nZgX+OrKzQ6TfQ7NSrFLjXclVVVUDWBQAAQGMhHUo1lJKSovT0dH3wwQfN7jNr1ixNnz7de7uyslJpaWnKzc1VYmKi32vyeDwqLCxUTk6OnE6n39cPNXbq1069SvQb6UKx3/z8wK0dFeVRVlahiotzVFcXGv0Gip16lb7vN1Cv5fozrAEAABB4YRVK7du3T5988olSUlKa3cflcjX5q31OpzOg/xAL9Pqhxk792qlXiX4jXSj1W1dnxXM4bRHUSPbqVQrcazlUfj4AAADsIKih1MGDB/Xhhx96b5eUlGjnzp3q2rWrunbtKrfbrcsuu0wpKSnas2eP7r77bnXv3l2XXnppEKsGAAAAAADAsQpqKLVt2zaNGDHCe7v+1+7Gjx+vRYsWqbi4WMuXL9c333yjlJQUjRgxQqtWrVJCQkKwSgYAAAAAAIAfBDWUGj58uIwxzd7/t7/9zcJqAAAAAAAAYJUAfiA3AAAAAAAA0DRCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFguJtgFAABCk9sd7AoAAAAARDLOlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWC4m2AUAAAAAABCp3EXuYJcAhCzOlAIAAAAAAIDlCKUAAAAAAABgOUIpAAAAAAAAWC6oodTGjRs1duxYpaamyuFwaM2aNT73G2PkdruVmpqquLg4DR8+XLt27QpOsQAAAAAAAPCboIZShw4dUnZ2thYuXNjk/XPnztW8efO0cOFCbd26VcnJycrJydGBAwcsrhQAAAAAAAD+FNRP3xs1apRGjRrV5H3GGM2fP1+zZ8/WuHHjJEnLli1TUlKSVqxYoYkTJ1pZKgAAAAAAAPwoqKFUS0pKSlRWVqbc3FzvNpfLpWHDhmnz5s3NhlLV1dWqrq723q6srJQkeTweeTwev9dZv2Yg1g5FdurXTr1K9Bvp2tNvVBhfdTAqyuPz30hmp16l7/sM1M+uXf5MAAAACAUhG0qVlZVJkpKSkny2JyUlae/evc0+Lj8/X3PmzGm0vaCgQPHx8f4t8gcKCwsDtnYoslO/dupVot9I15Z+s7MDWIhFsrLsc3zt1KsUuJ/dqqqqgKwLAACAxkI2lKrncDh8bhtjGm37oVmzZmn69One25WVlUpLS1Nubq4SExP9Xp/H41FhYaFycnLkdDr9vn6osVO/dupVot9wlJ/f+n2jojzKyipUcXGO6urCs9+2sFO/dupV+r7fQP3s1p9hDQAAgMAL2VAqOTlZ0ndnTKWkpHi3l5eXNzp76odcLpdcLlej7U6nM6D/8Az0+qHGTv3aqVeJfsNJXV17HuO0RXBRz0792qlXKXA/u+H65wEAAEA4CtkrhmRkZCg5Odnn9Pyamhpt2LBBQ4cODWJlAAAAAAAAOFZBPVPq4MGD+vDDD723S0pKtHPnTnXt2lXHH3+8pk2bpry8PGVmZiozM1N5eXmKj4/XNddcE8SqAQAAAAAAcKyCGkpt27ZNI0aM8N6uvxbU+PHjtXTpUs2cOVOHDx/WpEmTVFFRocGDB6ugoEAJCQnBKhkAAAAAAAB+ENRQavjw4TLGNHu/w+GQ2+2W2+22rigAAAAAAAAEXMheUwoAAAAAAACRi1AKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAIAQtnHjRo0dO1apqalyOBxas2aNz/3GGLndbqWmpiouLk7Dhw/Xrl27fPaprq7WlClT1L17d3Xs2FEXXXSRPv30Uwu7AAAAaCyon74HAJGMDw4F4A+HDh1Sdna2fvazn+myyy5rdP/cuXM1b948LV26VH369NGDDz6onJwc7d69WwkJCZKkadOm6aWXXtLKlSvVrVs3zZgxQxdeeKG2b9+u6Ohoq1sCAACQRCgFAAAQ0kaNGqVRo0Y1eZ8xRvPnz9fs2bM1btw4SdKyZcuUlJSkFStWaOLEidq/f78WL16sZ555Ruedd54k6dlnn1VaWppef/11nX/++Zb1AgAA8EP8+h4AAECYKikpUVlZmXJzc73bXC6Xhg0bps2bN0uStm/fLo/H47NPamqq+vfv790HAAAgGDhTCgAAIEyVlZVJkpKSkny2JyUlae/evd59YmNj1aVLl0b71D++KdXV1aqurvberqyslCR5PB55PB6/1B9K6nuKxN5aw87927l3if6t6D/KhO65IPW1hXKNgWLn3qXv+w7Ua7+16xJKAQAAhDmHw+Fz2xjTaFtDR9snPz9fc+bMabS9oKBA8fHx7Ss0DBQWFga7hKCyc/927l2i/0D2n63sgK3tL1kHsoJdQtDYuXcpcK/9qqqqVu1HKAUAABCmkpOTJX13NlRKSop3e3l5uffsqeTkZNXU1KiiosLnbKny8nINHTq02bVnzZql6dOne29XVlYqLS1Nubm5SkxM9HcrQefxeFRYWKicnBw5nc5gl2M5O/dv594l+rei//xN+QFZ1x+iTJSyDmSpOKFYdY66YJdjKTv3Ln3ff6Be+/VnWB8NoRQAAECYysjIUHJysgoLC3XaaadJkmpqarRhwwY98sgjkqSBAwfK6XSqsLBQV155pSSptLRU7777rubOndvs2i6XSy6Xq9F2p9MZ0f9wjfT+jsbO/du5d4n+A9l/OAQedY66sKgzEOzcuxS4135r1ySUAgAACGEHDx7Uhx9+6L1dUlKinTt3qmvXrjr++OM1bdo05eXlKTMzU5mZmcrLy1N8fLyuueYaSVLnzp114403asaMGerWrZu6du2qO++8U1lZWd5P4wMAAAgGQikAAIAQtm3bNo0YMcJ7u/5X6saPH6+lS5dq5syZOnz4sCZNmqSKigoNHjxYBQUFSkhI8D7m8ccfV0xMjK688kodPnxYI0eO1NKlSxUdHW15PwAAAPUIpQAAAELY8OHDZYxp9n6HwyG32y23293sPh06dNCCBQu0YMGCAFQIAADQPvb87EMAAAAAAAAEFaEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALBcT7AIAO3O7WT+Y60tSfr5UVxf45wEAAAAA+OJMKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYLmYYBcAAAAAAEAw5W/KV52jLthlALbDmVIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALBfSoZTb7ZbD4fD5Sk5ODnZZAAAAAAAAOEYxwS7gaE455RS9/vrr3tvR0dFBrAYAAAAAAAD+EPKhVExMDGdHAQAAAAAARJiQD6U++OADpaamyuVyafDgwcrLy9MJJ5zQ7P7V1dWqrq723q6srJQkeTweeTwev9dXv2Yg1g5FdurXil6jAvwLtG0pvT39hlL9bV/7u8WjoiL/tSx93yf9Rh479Sp932eg/my2w99vAAAAoSKkQ6nBgwdr+fLl6tOnj7744gs9+OCDGjp0qHbt2qVu3bo1+Zj8/HzNmTOn0faCggLFx8cHrNbCwsKArR2K7NRvIHvNzg7Y0pKkV19t+2Pa0m8o1t9WWVn2eS1L9BvJ7NSrFLg/m6uqqgKyLgAAABoL6VBq1KhR3v/PysrSkCFDdOKJJ2rZsmWaPn16k4+ZNWuWz32VlZVKS0tTbm6uEhMT/V6jx+NRYWGhcnJy5HQ6/b5+qGlPv/n5ga1p1qzArGvFsQ2l742djq30fb/FxTmqq4v8n92oKI+ysug3EtmpV+n7fgP1Z3P9GdYAAAAIvJAOpRrq2LGjsrKy9MEHHzS7j8vlksvlarTd6XQGNDQK9Pqhpi391tUFupZArx+4YxuK3xs7HVtJqqtz2uIf8vXoN3LZqVcpcH822+nvcgAAgGAL8BVh/Ku6ulrvvfeeUlJSgl0KAAAAAAAAjkFIh1J33nmnNmzYoJKSEv3rX//S5ZdfrsrKSo0fPz7YpQEAAAAAAOAYhPSv73366af63//9X3311Vfq0aOHzjzzTL3xxhtKT08PdmkAAAAAAAA4BiEdSq1cuTLYJQAAAAAAACAAQvrX9wAAAAAAABCZCKUAAAAAAABgOUIpAAAAAAAAWI5QCgAAAAAAAJYjlAIAAAAAAIDlQvrT94DWcLsDs25UlJSdLeXnS3V1gXkOAAAAAADsijOlAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACW45pSAAAAAICQ5S5yB2ztKBOlbGUHbH0ALeNMKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5QilAAAAAAAAYDlCKQAAAAAAAFiOUAoAAAAAAACWI5QCAAAAAACA5WKCXQAAAAAAIHy5i9zBLgFAmCKU8pP8fKmuLjBru92BWReRry2vnagoKTs7sK/ltgrka7++XwAAAABAcPDrewAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAyxFKAQAAAAAAwHKEUgAAAAAAALAcoRQAAAAAAAAsRygFAAAAAAAAy8UEuwAcndsd3usDAAAAAAA0xJlSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLEUoBAAAAAADAcoRSAAAAAAAAsByhFAAAAAAAACxHKAUAAAAAAADLxQS7AASf2936faOipOxsKT9fqqsLWEkAAAAAACDCcaYUAAAAAAAALMeZUgAAAAAQwdxF7mbvizJRyla28jflq87Br0IAsBahFAAAAAAEUUuhEQBEMkIpAAAAAGgBoREABAbXlAIAAAAAAIDlCKUAAAAAAABgubAIpZ588kllZGSoQ4cOGjhwoP7xj38EuyQAAICww0wFAABCSciHUqtWrdK0adM0e/Zs7dixQ2effbZGjRqljz/+ONilAQAAhA1mKgAAEGpCPpSaN2+ebrzxRt1000368Y9/rPnz5ystLU2LFi0KdmkAAABhg5kKAACEmpAOpWpqarR9+3bl5ub6bM/NzdXmzZuDVBUAAEB4YaYCAAChKCbYBbTkq6++Um1trZKSkny2JyUlqaysrMnHVFdXq7q62nt7//79kqSvv/5aHo/H7zV6PB5VVVWppmaf6uqcfl8/1ERF2adfO/Uq0W+ko9/IZadepe/73bdvn5xO//d74MABSZIxxu9rB1M4zFSS9NiWxwKybr0ZQ2Y0e1/9THcsr61A1x9IUSZKp1Sdojlr56jOUef39Vv63vvDsXzvA917qIsyUd/9PRJVQ//0H+xyLGXn3qXv+w/2TBXSoVQ9h8Phc9sY02hbvfz8fM2ZM6fR9oyMjIDUBgAAIs+BAwfUuXPnYJfhd3afqfKVH+wSbIvvPQDY09FmqpAOpbp3767o6OhG7+CVl5c3eqev3qxZszR9+nTv7bq6On399dfq1q1bs0PXsaisrFRaWpo++eQTJSYm+n39UGOnfu3Uq0S/kY5+I5edepUC368xRgcOHFBqaqrf1w6mcJipgs1uP0sN2bl/O/cu0T/927d/O/cuhc5MFdKhVGxsrAYOHKjCwkJdeuml3u2FhYW6+OKLm3yMy+WSy+Xy2XbccccFskxJUmJioq1eyHbq1069SvQb6eg3ctmpVymw/UbiGVLhNFMFm91+lhqyc/927l2if/q3b/927l0K/kwV0qGUJE2fPl3XXXedBg0apCFDhuj3v/+9Pv74Y/385z8PdmkAAABhg5kKAACEmpAPpa666irt27dP999/v0pLS9W/f3+9+uqrSk9PD3ZpAAAAYYOZCgAAhJqQD6UkadKkSZo0aVKwy2iSy+XSfffd1+j09khlp37t1KtEv5GOfiOXnXqV7Nevv4XyTBVsdn9t2bl/O/cu0T/927d/O/cuhU7/DhNpn3kMAAAAAACAkBcV7AIAAAAAAABgP4RSAAAAAAAAsByhFAAAAAAAACxHKNUKTz75pDIyMtShQwcNHDhQ//jHP1rcf8OGDRo4cKA6dOigE044QU899ZRFlfpHW/otKiqSw+Fo9PX+++9bWHH7bNy4UWPHjlVqaqocDofWrFlz1MeE87Fta7/hfGzz8/N1xhlnKCEhQT179tQll1yi3bt3H/Vx4Xp829NvOB/fRYsWacCAAUpMTFRiYqKGDBmi1157rcXHhOuxbWuv4Xxcm5Kfny+Hw6Fp06a1uF+4Hl9Yzy4zTkN2m3kastMM1JDdZqKG7DYjNWSnmakhu89QDYXyTEUodRSrVq3StGnTNHv2bO3YsUNnn322Ro0apY8//rjJ/UtKSjR69GidffbZ2rFjh+6++27dfvvteuGFFyyuvH3a2m+93bt3q7S01PuVmZlpUcXtd+jQIWVnZ2vhwoWt2j/cj21b+60Xjsd2w4YNmjx5st544w0VFhbqyJEjys3N1aFDh5p9TDgf3/b0Wy8cj2+vXr308MMPa9u2bdq2bZvOPfdcXXzxxdq1a1eT+4fzsW1rr/XC8bg2tHXrVv3+97/XgAEDWtwvnI8vrGWnGachu808DdlpBmrIbjNRQ3abkRqy08zUkJ1nqIZCfqYyaNFPfvIT8/Of/9xnW79+/cwvf/nLJvefOXOm6devn8+2iRMnmjPPPDNgNfpTW/tdv369kWQqKiosqC5wJJnVq1e3uE+4H9sfak2/kXJsjTGmvLzcSDIbNmxodp9IOr6t6TeSjq8xxnTp0sX88Y9/bPK+SDq2xrTca6Qc1wMHDpjMzExTWFhohg0bZqZOndrsvpF2fBE4dp1xGrLbzNOQ3Waghuw2EzVkxxmpITvNTA3ZYYZqKBxmKs6UakFNTY22b9+u3Nxcn+25ubnavHlzk4/ZsmVLo/3PP/98bdu2TR6PJ2C1+kN7+q132mmnKSUlRSNHjtT69esDWWbQhPOxPRaRcGz3798vSeratWuz+0TS8W1Nv/XC/fjW1tZq5cqVOnTokIYMGdLkPpFybFvTa71wP66TJ0/WmDFjdN555x1130g5vggsZpy24efqO5F47O02EzVkpxmpITvNTA3ZaYZqKBxmqpiArRwBvvrqK9XW1iopKclne1JSksrKypp8TFlZWZP7HzlyRF999ZVSUlICVu+xak+/KSkp+v3vf6+BAwequrpazzzzjEaOHKmioiKdc845VpRtmXA+tu0RKcfWGKPp06frrLPOUv/+/ZvdL1KOb2v7DffjW1xcrCFDhujbb79Vp06dtHr1ap188slN7hvux7YtvYb7cZWklStX6q233tLWrVtbtX+4H19Ygxmnbez+cxWpx95uM1FDdpmRGrLTzNSQ3WaohsJlpiKUagWHw+Fz2xjTaNvR9m9qe6hqS799+/ZV3759vbeHDBmiTz75RL/+9a/D9oe3JeF+bNsiUo7tbbfdpnfeeUebNm066r6RcHxb22+4H9++fftq586d+uabb/TCCy9o/Pjx2rBhQ7ODRjgf27b0Gu7H9ZNPPtHUqVNVUFCgDh06tPpx4Xx8YS1mnNaz889VpB57u81EDdllRmrITjNTQ3aaoRoKp5mKX99rQffu3RUdHd3oHbTy8vJGCWK95OTkJvePiYlRt27dAlarP7Sn36aceeaZ+uCDD/xdXtCF87H1l3A7tlOmTNGLL76o9evXq1evXi3uGwnHty39NiWcjm9sbKxOOukkDRo0SPn5+crOztYTTzzR5L7hfmzb0mtTwum4bt++XeXl5Ro4cKBiYmIUExOjDRs26De/+Y1iYmJUW1vb6DHhfnxhDWactuHnqrFwP/Z2m4kastOM1JCdZqaG7DRDNRROMxWhVAtiY2M1cOBAFRYW+mwvLCzU0KFDm3zMkCFDGu1fUFCgQYMGyel0BqxWf2hPv03ZsWNH2J3a2RrhfGz9JVyOrTFGt912m/7yl79o3bp1ysjIOOpjwvn4tqffpoTL8W2KMUbV1dVN3hfOx7YpLfXalHA6riNHjlRxcbF27tzp/Ro0aJCuvfZa7dy5U9HR0Y0eE2nHF4HBjNM2/Fw1Fq7H3m4zUUPMSI3ZaWZqKJJnqIbCaqYK6GXUI8DKlSuN0+k0ixcvNv/+97/NtGnTTMeOHc2ePXuMMcb88pe/NNddd513///+978mPj7e3HHHHebf//63Wbx4sXE6neb5558PVgtt0tZ+H3/8cbN69Wrzn//8x7z77rvml7/8pZFkXnjhhWC10GoHDhwwO3bsMDt27DCSzLx588yOHTvM3r17jTGRd2zb2m84H9tbb73VdO7c2RQVFZnS0lLvV1VVlXefSDq+7ek3nI/vrFmzzMaNG01JSYl55513zN13322ioqJMQUGBMSayjm1bew3n49qchp8UE0nHF9ay04zTkN1mnobsNAM1ZLeZqCG7zUgN2WlmaogZqrFQnakIpVrht7/9rUlPTzexsbHm9NNP9/kI0fHjx5thw4b57F9UVGROO+00Exsba3r37m0WLVpkccXHpi39PvLII+bEE080HTp0MF26dDFnnXWWeeWVV4JQddvVf+xnw6/x48cbYyLv2La133A+tk31KcksWbLEu08kHd/29BvOx/eGG27w/hnVo0cPM3LkSO+AYUxkHdu29hrOx7U5DQeoSDq+sJ5dZpyG7DbzNGSnGaghu81EDdltRmrITjNTQ8xQjYXqTOUw5v9fuQoAAAAAAACwCNeUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQAAAAAAAGA5QikAAAAAAABYjlAKAAAAAAAAliOUAgAAAAAAgOUIpQD41caNGzV27FilpqbK4XBozZo1bXr88OHDNW3atGbvr66u1imnnKJbbrml0X0zZ85Uenq6Kisr21j1sVm/fr0uvPBC9ejRQx06dNCJJ56oq666Shs3bvTuU1RUJIfD4f3q0aOHRo0apbfffttnrc2bNys6OloXXHCBpT0AAIDQwkzFTAXYAaEUAL86dOiQsrOztXDhwoCs73K5tHz5ci1dulRr1671bn/jjTf0+OOPa+nSpUpMTPTrcxpjdOTIkSbve/LJJzVy5Eh169ZNq1at0nvvvadnnnlGQ4cO1R133NFo/927d6u0tFSvvPKKKioqdMEFF2j//v3e+59++mlNmTJFmzZt0scff+zXPgAAQPhgpmKmAmzBAECASDKrV69utP23v/2tOemkk4zL5TI9e/Y0l112mTHGmPHjxxtJPl8lJSVNru12u82PfvQjU1FRYQ4fPmz69etnpk6daowx5p///Kc5++yzTYcOHUyvXr3MlClTzMGDB72PfeaZZ8zAgQNNp06dTFJSkvnf//1f88UXX3jvX79+vZFk1q5dawYOHGicTqdZt25doxr27t1rnE6nueOOO5qssa6urtGaFRUV3m2bNm3yPo8xxhw8eNAkJCSY999/31x11VVmzpw5Ta4LAADshZmKmQqIVJwpBcBS27Zt0+233677779fu3fv1tq1a3XOOedIkp544gkNGTJEN998s0pLS1VaWqq0tLQm15k9e7ZSUlJ0++2361e/+pUkKT8/X8XFxTr//PM1btw4vfPOO1q1apU2bdqk2267zfvYmpoaPfDAA3r77be1Zs0alZSUaMKECY2eY+bMmcrPz9d7772nAQMGNLr/hRdekMfj0cyZM5us0eFwtPi9iIuLkyR5PB5J0qpVq9S3b1/17dtXP/3pT7VkyRIZY1pcAwAA2BMz1feYqYAwFuxUDEDkUhPv6r3wwgsmMTHRVFZWNvmYYcOGed+dO5p///vfpkOHDiY2Nta8+eabxhhjrrvuOnPLLbf47PePf/zDREVFmcOHDze5zptvvmkkmQMHDhhjvn8Hbs2aNS0+/89//nOTmJjos+355583HTt29H698847PmvWv6v31VdfmYsuusgkJCR431EcOnSomT9/vjHGGI/HY7p3724KCwtb9b0AAACRi5mKmQqIVJwpBcBSOTk5Sk9P1wknnKDrrrtOzz33nKqqqtq11o9//GNddtllysnJ0RlnnCFJ2r59u5YuXapOnTp5v84//3zV1dWppKREkrRjxw5dfPHFSk9PV0JCgoYPHy5Jja43MGjQoKPW0PCdu/PPP187d+7UK6+8okOHDqm2ttbn/l69eqlTp07q3r273nvvPf35z39Wz549tXv3br355pu6+uqrJUkxMTG66qqr9PTTT7frewMAACIbMxUzFRAJYoJdAAB7SUhI0FtvvaWioiIVFBTo3nvvldvt1tatW3Xccce1eb2YmBjFxHz/R1ldXZ0mTpyo22+/vdG+xx9/vA4dOqTc3Fzl5ubq2WefVY8ePfTxxx/r/PPPV01Njc/+HTt2bPG5MzMztX//fpWVlSk5OVmS1KlTJ5100kk+Nf3QP/7xDyUmJqpHjx4+Fw9dvHixjhw5oh/96EfebcYYOZ1OVVRUqEuXLkf/ZgAAANtgpmKmAiIBZ0oBsFxMTIzOO+88zZ07V++884727NmjdevWSZJiY2MbvRPWFqeffrp27dqlk046qdFXbGys3n//fX311Vd6+OGHdfbZZ6tfv34qLy9v13NdfvnlcjqdeuSRR1r9mIyMDJ144ok+w9ORI0e0fPlyPfbYY9q5c6f36+2331Z6erqee+65dtUHAAAiGzMVMxUQ7jhTCoBfHTx4UB9++KH3dklJiXbu3KmuXbvq+OOP18svv6z//ve/Ouecc9SlSxe9+uqrqqurU9++fSVJvXv31r/+9S/t2bNHnTp1UteuXRUV1fr8/K677tKZZ56pyZMn6+abb1bHjh313nvvqbCwUAsWLNDxxx+v2NhYLViwQD//+c/17rvv6oEHHmhXr8cff7wee+wxTZ06VV9//bUmTJigjIwMff3113r22WclSdHR0Udd5+WXX1ZFRYVuvPFGde7c2ee+yy+/XIsXL/a5qCgAAIh8zFTMVIAtBPuiVgAiS/3FJxt+jR8/3hjz3QUyhw0bZrp06WLi4uLMgAEDzKpVq7yP3717tznzzDNNXFxcix9fXG/8+PHm4osv9tn25ptvmpycHNOpUyfTsWNHM2DAAPPQQw9571+xYoXp3bu3cblcZsiQIebFF180ksyOHTt8evjhRw23pLCw0IwaNcp07drVxMTEmKSkJHPJJZd4P5b4aGteeOGFZvTo0U2uvX37diPJbN++vVW1AACAyMBMxUwF2IHDGD4bEwAAAAAAANbimlIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMByhFIAAAAAAACwHKEUAAAAAAAALEcoBQAAAAAAAMsRSgEAAAAAAMBy/w8c4Bg3WoZICgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Filter for left and stayed\n",
    "retention_0 = student_df[student_df['1st Year Retention'] == 0]['1st Year GPA']\n",
    "retention_1 = student_df[student_df['1st Year Retention'] == 1]['1st Year GPA']\n",
    "\n",
    "# Set up the figure and axes\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Plot histograms on separate axes\n",
    "retention_0.hist(ax=axes[0], alpha=0.5, bins=20, color='blue')\n",
    "retention_1.hist(ax=axes[1], alpha=0.5, bins=20, color='green')\n",
    "\n",
    "# Adding titles and labels to the first subplot\n",
    "axes[0].set_title('1st Year GPA for Retention = 0')\n",
    "axes[0].set_xlabel('1st Year GPA')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Adding titles and labels to the second subplot\n",
    "axes[1].set_title('1st Year GPA for Retention = 1')\n",
    "axes[1].set_xlabel('1st Year GPA')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "# Layout adjustment to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46527559-f7b1-491d-9ca7-aa7cddc104d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "# Test for normality\n",
    "shapiro_0 = shapiro(retention_0.dropna())\n",
    "shapiro_1 = shapiro(retention_1.dropna())\n",
    "\n",
    "shapiro_0, shapiro_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96dbbdfe-3d94-4e9f-b425-7cab6c779d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "# Test for equal variances\n",
    "levene_test = levene(retention_0.dropna(), retention_1.dropna())\n",
    "\n",
    "levene_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53fe9ef-bedd-45fe-80df-d5b09440e6c0",
   "metadata": {},
   "source": [
    "#### Not normal or homogenious variances, so we'll do Mann-Whitney instead of t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf07bf1-1a8a-4b1c-b037-f84134be3fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "# Mann-Whitney U test\n",
    "mwu_test = mannwhitneyu(retention_0.dropna(), retention_1.dropna())\n",
    "\n",
    "mwu_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e58c755-0af2-4227-85f3-7c232c030636",
   "metadata": {},
   "source": [
    "#### Result confirms there is a significant difference between the stayed and left groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd482831-eccd-4ed5-985a-15c6ec446a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for 'Total Earned Hours' based on retention status\n",
    "retention_hours_0 = student_df[student_df['1st Year Retention'] == 0]['Total Earned Hours']\n",
    "retention_hours_1 = student_df[student_df['1st Year Retention'] == 1]['Total Earned Hours']\n",
    "\n",
    "# Set up the figure and axes for plotting\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
    "\n",
    "# Plot histograms on separate axes for each group\n",
    "retention_hours_0.hist(ax=axes[0], alpha=0.5, bins=20, color='blue')\n",
    "retention_hours_1.hist(ax=axes[1], alpha=0.5, bins=20, color='green')\n",
    "\n",
    "# Adding titles and labels to the first subplot\n",
    "axes[0].set_title('Total Earned Hours for Retention = 0')\n",
    "axes[0].set_xlabel('Total Earned Hours')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "\n",
    "# Adding titles and labels to the second subplot\n",
    "axes[1].set_title('Total Earned Hours for Retention = 1')\n",
    "axes[1].set_xlabel('Total Earned Hours')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "\n",
    "# Layout adjustment to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f306823b-bb79-48eb-ba14-6d3e7f164968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame named 'student_df'\n",
    "retention_hours_0 = student_df[student_df['1st Year Retention'] == 0]['Total Earned Hours']\n",
    "retention_hours_1 = student_df[student_df['1st Year Retention'] == 1]['Total Earned Hours']\n",
    "# Normality test for each group\n",
    "norm_test_0 = shapiro(retention_hours_0.dropna())\n",
    "norm_test_1 = shapiro(retention_hours_1.dropna())\n",
    "\n",
    "norm_test_0, norm_test_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10405483-4438-4db2-b848-8be019ac463e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variance equality test\n",
    "variance_test = levene(retention_hours_0.dropna(), retention_hours_1.dropna())\n",
    "\n",
    "variance_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d843d30f-8223-4dc8-85db-1067753dc3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U test\n",
    "mwu_test_hours = mannwhitneyu(retention_hours_0.dropna(), retention_hours_1.dropna())\n",
    "\n",
    "mwu_test_hours\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf5546-af10-4ee2-99bc-af9343a6d28a",
   "metadata": {},
   "source": [
    "#### Confirmed significant difference again."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf960f9-368c-47f8-9eb7-a117b1c2860d",
   "metadata": {},
   "source": [
    "## 4. Model Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47465b6d-f8db-420e-bec6-c82027682683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PIDM</th>\n",
       "      <th>1st Year GPA</th>\n",
       "      <th>1st Year Retention</th>\n",
       "      <th>Total Earned Hours</th>\n",
       "      <th>Advisor</th>\n",
       "      <th>Cohort_202109F</th>\n",
       "      <th>Cohort_202209F</th>\n",
       "      <th>SEX_F</th>\n",
       "      <th>SEX_M</th>\n",
       "      <th>Degree_BA</th>\n",
       "      <th>...</th>\n",
       "      <th>Dorm_Claver Hall</th>\n",
       "      <th>Dorm_Commuter</th>\n",
       "      <th>Dorm_Gonzaga Hall</th>\n",
       "      <th>Dorm_Jogues Hall</th>\n",
       "      <th>Dorm_Loyola Hall</th>\n",
       "      <th>Dorm_Regis Hall</th>\n",
       "      <th>College_CAS</th>\n",
       "      <th>College_DSB</th>\n",
       "      <th>College_EGAN</th>\n",
       "      <th>College_SEC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.49</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.18</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.86</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3.84</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PIDM  1st Year GPA  1st Year Retention  Total Earned Hours  Advisor  \\\n",
       "0     1          2.49                   1                  36      1.0   \n",
       "1     2          3.18                   1                  47      2.0   \n",
       "2     3          2.86                   1                  46      3.0   \n",
       "3     4          3.84                   1                  45      4.0   \n",
       "4     5          2.69                   1                  42      5.0   \n",
       "\n",
       "   Cohort_202109F  Cohort_202209F  SEX_F  SEX_M  Degree_BA  ...  \\\n",
       "0               1               0      0      1          0  ...   \n",
       "1               1               0      0      1          0  ...   \n",
       "2               1               0      0      1          0  ...   \n",
       "3               1               0      0      1          0  ...   \n",
       "4               1               0      0      1          0  ...   \n",
       "\n",
       "   Dorm_Claver Hall  Dorm_Commuter  Dorm_Gonzaga Hall  Dorm_Jogues Hall  \\\n",
       "0                 0              0                  0                 0   \n",
       "1                 0              1                  0                 0   \n",
       "2                 0              0                  0                 0   \n",
       "3                 0              0                  1                 0   \n",
       "4                 0              1                  0                 0   \n",
       "\n",
       "   Dorm_Loyola Hall  Dorm_Regis Hall  College_CAS  College_DSB  College_EGAN  \\\n",
       "0                 0                0            0            0             0   \n",
       "1                 0                0            1            0             0   \n",
       "2                 0                1            1            0             0   \n",
       "3                 0                0            0            1             0   \n",
       "4                 0                0            0            1             0   \n",
       "\n",
       "   College_SEC  \n",
       "0            1  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Select categorical columns for one-hot encoding\n",
    "categorical_cols = ['Cohort', 'SEX', 'Degree', 'Major 1', 'Dorm', 'College']\n",
    "\n",
    "# Perform one-hot encoding\n",
    "student_df_encoded = pd.get_dummies(student_df, columns=categorical_cols)\n",
    "\n",
    "student_df_encoded.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c5aa785c-26a2-41eb-8902-c46e3c97c2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2575 entries, 0 to 2583\n",
      "Data columns (total 60 columns):\n",
      " #   Column                                       Non-Null Count  Dtype  \n",
      "---  ------                                       --------------  -----  \n",
      " 0   PIDM                                         2575 non-null   int64  \n",
      " 1   1st Year GPA                                 2575 non-null   float64\n",
      " 2   1st Year Retention                           2575 non-null   int64  \n",
      " 3   Total Earned Hours                           2575 non-null   int64  \n",
      " 4   Advisor                                      2575 non-null   float64\n",
      " 5   Cohort_202109F                               2575 non-null   uint8  \n",
      " 6   Cohort_202209F                               2575 non-null   uint8  \n",
      " 7   SEX_F                                        2575 non-null   uint8  \n",
      " 8   SEX_M                                        2575 non-null   uint8  \n",
      " 9   Degree_BA                                    2575 non-null   uint8  \n",
      " 10  Degree_BS                                    2575 non-null   uint8  \n",
      " 11  Degree_BSW                                   2575 non-null   uint8  \n",
      " 12  Major 1_Accounting                           2575 non-null   uint8  \n",
      " 13  Major 1_American Studies                     2575 non-null   uint8  \n",
      " 14  Major 1_Biology                              2575 non-null   uint8  \n",
      " 15  Major 1_Biomedical Engineering               2575 non-null   uint8  \n",
      " 16  Major 1_Business Analytics                   2575 non-null   uint8  \n",
      " 17  Major 1_Chemistry                            2575 non-null   uint8  \n",
      " 18  Major 1_Communication                        2575 non-null   uint8  \n",
      " 19  Major 1_Computer Science                     2575 non-null   uint8  \n",
      " 20  Major 1_DSB Undeclared                       2575 non-null   uint8  \n",
      " 21  Major 1_Digital Journalism                   2575 non-null   uint8  \n",
      " 22  Major 1_Economics                            2575 non-null   uint8  \n",
      " 23  Major 1_Electrical and Computer Engineering  2575 non-null   uint8  \n",
      " 24  Major 1_English                              2575 non-null   uint8  \n",
      " 25  Major 1_Finance                              2575 non-null   uint8  \n",
      " 26  Major 1_History                              2575 non-null   uint8  \n",
      " 27  Major 1_Information Systems & Ops Mgmt       2575 non-null   uint8  \n",
      " 28  Major 1_International Business               2575 non-null   uint8  \n",
      " 29  Major 1_International Studies                2575 non-null   uint8  \n",
      " 30  Major 1_Management                           2575 non-null   uint8  \n",
      " 31  Major 1_Marketing                            2575 non-null   uint8  \n",
      " 32  Major 1_Mathematics                          2575 non-null   uint8  \n",
      " 33  Major 1_Mechanical Engineering               2575 non-null   uint8  \n",
      " 34  Major 1_Modern Languages                     2575 non-null   uint8  \n",
      " 35  Major 1_Nursing                              2575 non-null   uint8  \n",
      " 36  Major 1_Physics                              2575 non-null   uint8  \n",
      " 37  Major 1_Politics                             2575 non-null   uint8  \n",
      " 38  Major 1_Program on the Environment           2575 non-null   uint8  \n",
      " 39  Major 1_Psychology                           2575 non-null   uint8  \n",
      " 40  Major 1_Public Health                        2575 non-null   uint8  \n",
      " 41  Major 1_Religious Studies                    2575 non-null   uint8  \n",
      " 42  Major 1_SOE Undeclared                       2575 non-null   uint8  \n",
      " 43  Major 1_Social Work                          2575 non-null   uint8  \n",
      " 44  Major 1_Sociology and Anthropology           2575 non-null   uint8  \n",
      " 45  Major 1_Sports Media                         2575 non-null   uint8  \n",
      " 46  Major 1_Undeclared                           2575 non-null   uint8  \n",
      " 47  Major 1_Visual & Performing Arts             2575 non-null   uint8  \n",
      " 48  Dorm_1036 North Benson Road                  2575 non-null   uint8  \n",
      " 49  Dorm_Campion Hall                            2575 non-null   uint8  \n",
      " 50  Dorm_Claver Hall                             2575 non-null   uint8  \n",
      " 51  Dorm_Commuter                                2575 non-null   uint8  \n",
      " 52  Dorm_Gonzaga Hall                            2575 non-null   uint8  \n",
      " 53  Dorm_Jogues Hall                             2575 non-null   uint8  \n",
      " 54  Dorm_Loyola Hall                             2575 non-null   uint8  \n",
      " 55  Dorm_Regis Hall                              2575 non-null   uint8  \n",
      " 56  College_CAS                                  2575 non-null   uint8  \n",
      " 57  College_DSB                                  2575 non-null   uint8  \n",
      " 58  College_EGAN                                 2575 non-null   uint8  \n",
      " 59  College_SEC                                  2575 non-null   uint8  \n",
      "dtypes: float64(2), int64(3), uint8(55)\n",
      "memory usage: 259.0 KB\n"
     ]
    }
   ],
   "source": [
    "student_df_encoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "32055311-4f34-49ca-a443-b21dad274302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2334\n",
       "0     241\n",
       "Name: 1st Year Retention, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_df_encoded['1st Year Retention'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92ba14d6-eb4e-45b0-98c1-085d8a541268",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = student_df_encoded.columns[(student_df_encoded.columns != 'PIDM') & (student_df_encoded.columns != '1st Year Retention')]\n",
    "target = \"1st Year Retention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "130cc9e8-4c3e-42b6-89f4-2a225195ad4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2060, 58), (2060,), (515, 58), (515,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = student_df_encoded[features]\n",
    "y = student_df_encoded[target]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=0)\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4c56b8f-b28f-43e0-b39e-b64efb7ad1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "def train_test2(X_train, X_test, y_train, y_test, param_grid, clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print(\"*** Parameter estimation results: \")\n",
    "    print(clf.cv_results_)\n",
    "    print()\n",
    "\n",
    "    print(\"*** Grid scores: \")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    params = clf.cv_results_['params']\n",
    "\n",
    "    for mean, std, param in zip(means, stds, params):\n",
    "        print(f\"{round(mean, 3)} (+/-{round(std*2, 3)}) for {param}\")\n",
    "    print()\n",
    "\n",
    "    print(\"*** Highest accuracy score: \")\n",
    "    print(f\"{round(clf.best_score_, 3)}\")\n",
    "    print()\n",
    "\n",
    "    print(\"*** Best parameters set found: \")\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "\n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "\n",
    "    print(\"*** Classification report for the best parameters set: \")\n",
    "    print(metrics.classification_report(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "    print(\"*** Confusion matrix for the best parameters set: \")\n",
    "    print(metrics.confusion_matrix(y_true, y_pred))\n",
    "    print()\n",
    "\n",
    "    print(\"*** Final accuracy score: \")\n",
    "    test_score = round(clf.score(X_test, y_test), 3)\n",
    "    print(test_score)\n",
    "\n",
    "    return clf, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5498129d-903c-4492-93e5-86657c782da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = 5\n",
    "summary = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fee27-11a6-4513-87d8-49797f80460a",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15bc9fc9-94d7-4104-a35c-69318d534c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\"n_neighbors\": [1, 3, 10, 30, 100]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec9c7930-9ff4-4f7c-af02-575a2f6fdad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;n_neighbors&#x27;: [1, 3, 10, 30, 100]}])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{&#x27;n_neighbors&#x27;: [1, 3, 10, 30, 100]}])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid=[{'n_neighbors': [1, 3, 10, 30, 100]}])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knc = GridSearchCV(KNeighborsClassifier(), param_grid, cv=cv)\n",
    "knc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c60d1d5f-3345-43a3-8658-f8d7d791f491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.        , 0.00748734, 0.00452309, 0.00163207, 0.00679717]), 'std_fit_time': array([0.        , 0.00721843, 0.0064743 , 0.00208174, 0.00556986]), 'mean_score_time': array([0.09315948, 0.0257443 , 0.03215632, 0.03100963, 0.043437  ]), 'std_score_time': array([0.11180801, 0.00719405, 0.00194015, 0.00405661, 0.00574952]), 'param_n_neighbors': masked_array(data=[1, 3, 10, 30, 100],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'n_neighbors': 1}, {'n_neighbors': 3}, {'n_neighbors': 10}, {'n_neighbors': 30}, {'n_neighbors': 100}], 'split0_test_score': array([0.97572816, 0.98058252, 0.97572816, 0.96601942, 0.92718447]), 'split1_test_score': array([0.97330097, 0.98058252, 0.97815534, 0.96359223, 0.92475728]), 'split2_test_score': array([0.97572816, 0.97087379, 0.97330097, 0.94902913, 0.91262136]), 'split3_test_score': array([0.97087379, 0.96116505, 0.96359223, 0.94660194, 0.91019417]), 'split4_test_score': array([0.97087379, 0.98058252, 0.98058252, 0.95631068, 0.91990291]), 'mean_test_score': array([0.97330097, 0.97475728, 0.97427184, 0.95631068, 0.91893204]), 'std_test_score': array([0.00217094, 0.00776699, 0.00586556, 0.00767543, 0.00662048]), 'rank_test_score': array([3, 1, 2, 4, 5])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.973 (+/-0.004) for {'n_neighbors': 1}\n",
      "0.975 (+/-0.016) for {'n_neighbors': 3}\n",
      "0.974 (+/-0.012) for {'n_neighbors': 10}\n",
      "0.956 (+/-0.015) for {'n_neighbors': 30}\n",
      "0.919 (+/-0.013) for {'n_neighbors': 100}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.975\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'n_neighbors': 3}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.88        51\n",
      "           1       0.99      0.98      0.99       464\n",
      "\n",
      "    accuracy                           0.98       515\n",
      "   macro avg       0.93      0.94      0.94       515\n",
      "weighted avg       0.98      0.98      0.98       515\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[ 46   5]\n",
      " [  7 457]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.977\n"
     ]
    }
   ],
   "source": [
    "knc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, knc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f2cae2a-9544-46e3-84d9-902371b4c302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.977}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary[\"k-NNs\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba4b04b-d9de-417a-ade5-188697432b81",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61408d38-cd9d-450f-83da-55ab914c16f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.03567228, 0.00490193, 0.03168373, 0.00253129, 0.03361111,\n",
      "       0.00253339, 0.03451085, 0.00484581, 0.02992043, 0.00463624,\n",
      "       0.02840176, 0.00527048, 0.02724881, 0.0063355 ]), 'std_fit_time': array([0.00605396, 0.00092445, 0.00527406, 0.00220546, 0.00945105,\n",
      "       0.00208033, 0.00782956, 0.00635666, 0.01037216, 0.00623534,\n",
      "       0.00475742, 0.00267638, 0.00513868, 0.00590643]), 'mean_score_time': array([0.00161219, 0.00141525, 0.00308104, 0.00040283, 0.00020223,\n",
      "       0.00366812, 0.00366549, 0.        , 0.00040464, 0.00170283,\n",
      "       0.        , 0.00467701, 0.        , 0.        ]), 'std_score_time': array([0.00080619, 0.00047255, 0.0022742 , 0.00049343, 0.00040445,\n",
      "       0.00586515, 0.00416192, 0.        , 0.00080929, 0.00340567,\n",
      "       0.        , 0.00554058, 0.        , 0.        ]), 'param_C': masked_array(data=[0.01, 0.01, 0.03, 0.03, 0.1, 0.1, 0.3, 0.3, 1, 1, 3, 3,\n",
      "                   10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['lbfgs', 'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
      "                   'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
      "                   'liblinear', 'lbfgs', 'liblinear', 'lbfgs',\n",
      "                   'liblinear'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.01, 'solver': 'lbfgs'}, {'C': 0.01, 'solver': 'liblinear'}, {'C': 0.03, 'solver': 'lbfgs'}, {'C': 0.03, 'solver': 'liblinear'}, {'C': 0.1, 'solver': 'lbfgs'}, {'C': 0.1, 'solver': 'liblinear'}, {'C': 0.3, 'solver': 'lbfgs'}, {'C': 0.3, 'solver': 'liblinear'}, {'C': 1, 'solver': 'lbfgs'}, {'C': 1, 'solver': 'liblinear'}, {'C': 3, 'solver': 'lbfgs'}, {'C': 3, 'solver': 'liblinear'}, {'C': 10, 'solver': 'lbfgs'}, {'C': 10, 'solver': 'liblinear'}], 'split0_test_score': array([0.98300971, 0.94174757, 0.98543689, 0.95873786, 0.98543689,\n",
      "       0.97087379, 0.98543689, 0.98543689, 0.97815534, 0.98786408,\n",
      "       0.98058252, 0.98300971, 0.97815534, 0.98058252]), 'split1_test_score': array([0.97815534, 0.9538835 , 0.98058252, 0.96116505, 0.98058252,\n",
      "       0.97330097, 0.98300971, 0.98543689, 0.98543689, 0.98786408,\n",
      "       0.98543689, 0.98543689, 0.98543689, 0.98300971]), 'split2_test_score': array([0.9684466 , 0.94417476, 0.9684466 , 0.94660194, 0.97815534,\n",
      "       0.97815534, 0.98300971, 0.98543689, 0.98786408, 0.98786408,\n",
      "       0.98786408, 0.98786408, 0.98543689, 0.98786408]), 'split3_test_score': array([0.9684466 , 0.9368932 , 0.97330097, 0.94417476, 0.97087379,\n",
      "       0.96116505, 0.97087379, 0.9684466 , 0.97572816, 0.97815534,\n",
      "       0.98058252, 0.98058252, 0.98058252, 0.98058252]), 'split4_test_score': array([0.98543689, 0.93932039, 0.98786408, 0.95873786, 0.98786408,\n",
      "       0.97330097, 0.98543689, 0.97572816, 0.98543689, 0.97815534,\n",
      "       0.98300971, 0.98300971, 0.98786408, 0.98543689]), 'mean_test_score': array([0.97669903, 0.94320388, 0.97912621, 0.9538835 , 0.98058252,\n",
      "       0.97135922, 0.9815534 , 0.98009709, 0.98252427, 0.98398058,\n",
      "       0.98349515, 0.98398058, 0.98349515, 0.98349515]), 'std_test_score': array([0.00713444, 0.00586556, 0.00729772, 0.00703465, 0.00594536,\n",
      "       0.00561934, 0.00544902, 0.00693343, 0.00470649, 0.00475629,\n",
      "       0.00283056, 0.00247525, 0.00356722, 0.00283056]), 'rank_test_score': array([11, 14, 10, 13,  8, 12,  7,  9,  6,  1,  3,  1,  5,  3])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.977 (+/-0.014) for {'C': 0.01, 'solver': 'lbfgs'}\n",
      "0.943 (+/-0.012) for {'C': 0.01, 'solver': 'liblinear'}\n",
      "0.979 (+/-0.015) for {'C': 0.03, 'solver': 'lbfgs'}\n",
      "0.954 (+/-0.014) for {'C': 0.03, 'solver': 'liblinear'}\n",
      "0.981 (+/-0.012) for {'C': 0.1, 'solver': 'lbfgs'}\n",
      "0.971 (+/-0.011) for {'C': 0.1, 'solver': 'liblinear'}\n",
      "0.982 (+/-0.011) for {'C': 0.3, 'solver': 'lbfgs'}\n",
      "0.98 (+/-0.014) for {'C': 0.3, 'solver': 'liblinear'}\n",
      "0.983 (+/-0.009) for {'C': 1, 'solver': 'lbfgs'}\n",
      "0.984 (+/-0.01) for {'C': 1, 'solver': 'liblinear'}\n",
      "0.983 (+/-0.006) for {'C': 3, 'solver': 'lbfgs'}\n",
      "0.984 (+/-0.005) for {'C': 3, 'solver': 'liblinear'}\n",
      "0.983 (+/-0.007) for {'C': 10, 'solver': 'lbfgs'}\n",
      "0.983 (+/-0.006) for {'C': 10, 'solver': 'liblinear'}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.984\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'C': 1, 'solver': 'liblinear'}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        51\n",
      "           1       0.99      0.99      0.99       464\n",
      "\n",
      "    accuracy                           0.98       515\n",
      "   macro avg       0.95      0.94      0.94       515\n",
      "weighted avg       0.98      0.98      0.98       515\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[ 45   6]\n",
      " [  4 460]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.977, 'Logistic Regression': 0.981}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10], \"solver\": [\"lbfgs\", \"liblinear\"]}]\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = GridSearchCV(LogisticRegression(), param_grid, cv=cv)\n",
    "lr, score = train_test2(X_train, X_test, y_train, y_test, param_grid, lr)\n",
    "summary[\"Logistic Regression\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674ebf5f-ec6c-4c46-88c7-9826f8cd041e",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3f37fed-68c3-4c6f-af09-845f6fec303e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00162592, 0.00563641, 0.00450149, 0.00664363]), 'std_fit_time': array([0.00164472, 0.00561329, 0.00241446, 0.00238692]), 'mean_score_time': array([0.00183148, 0.00101514, 0.00261407, 0.00146623]), 'std_score_time': array([0.00277472, 0.00065641, 0.0031905 , 0.00052425]), 'param_max_depth': masked_array(data=[1, 3, 10, None],\n",
      "             mask=[False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1}, {'max_depth': 3}, {'max_depth': 10}, {'max_depth': None}], 'split0_test_score': array([0.98058252, 0.97815534, 0.97087379, 0.9684466 ]), 'split1_test_score': array([0.98058252, 0.98543689, 0.97815534, 0.97572816]), 'split2_test_score': array([0.9684466 , 0.98058252, 0.98300971, 0.98300971]), 'split3_test_score': array([0.97087379, 0.97087379, 0.97572816, 0.97572816]), 'split4_test_score': array([0.98543689, 0.97572816, 0.97572816, 0.97572816]), 'mean_test_score': array([0.97718447, 0.97815534, 0.97669903, 0.97572816]), 'std_test_score': array([0.00644005, 0.00485437, 0.00394371, 0.00460526]), 'rank_test_score': array([2, 1, 3, 4])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.977 (+/-0.013) for {'max_depth': 1}\n",
      "0.978 (+/-0.01) for {'max_depth': 3}\n",
      "0.977 (+/-0.008) for {'max_depth': 10}\n",
      "0.976 (+/-0.009) for {'max_depth': None}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.978\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'max_depth': 3}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.96      0.92        51\n",
      "           1       1.00      0.99      0.99       464\n",
      "\n",
      "    accuracy                           0.98       515\n",
      "   macro avg       0.94      0.97      0.96       515\n",
      "weighted avg       0.99      0.98      0.98       515\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[ 49   2]\n",
      " [  6 458]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.977, 'Logistic Regression': 0.981, 'Decision Trees': 0.984}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"max_depth\": [1, 3, 10, None]}]\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dtc = GridSearchCV(DecisionTreeClassifier(random_state=0), param_grid, cv=cv)\n",
    "dtc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, dtc)\n",
    "summary[\"Decision Trees\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f1c1c2-d0d8-4a72-a2ee-eb4654d5d9f0",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bdfd200-b957-42a4-814c-f961754b1dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.00334506, 0.00312657, 0.0094521 , 0.02187538, 0.08979135,\n",
      "       0.25779133, 0.95813518, 0.00390296, 0.00902915, 0.01482835,\n",
      "       0.0449573 , 0.11679473, 0.36067715, 1.11318092, 0.00574145,\n",
      "       0.0100811 , 0.0170258 , 0.05124593, 0.15463114, 0.43897715,\n",
      "       1.58407412, 0.00472956, 0.0059968 , 0.02124281, 0.05281119,\n",
      "       0.18605027, 0.58578548, 1.79839749]), 'std_fit_time': array([0.00669012, 0.00625315, 0.00776247, 0.00647431, 0.00878371,\n",
      "       0.02585579, 0.1332892 , 0.0023502 , 0.00900284, 0.0036862 ,\n",
      "       0.01672933, 0.0108599 , 0.09807902, 0.04611813, 0.00522366,\n",
      "       0.00561207, 0.00046074, 0.00834721, 0.00895664, 0.03725254,\n",
      "       0.07498539, 0.00385651, 0.00265173, 0.00163052, 0.0009976 ,\n",
      "       0.01631863, 0.06356485, 0.10700273]), 'mean_score_time': array([0.        , 0.00301962, 0.00312524, 0.00705633, 0.0024066 ,\n",
      "       0.00334978, 0.04233556, 0.00100136, 0.00318661, 0.00180149,\n",
      "       0.0043014 , 0.00398221, 0.01364632, 0.05380573, 0.00061851,\n",
      "       0.00124712, 0.00049071, 0.00497403, 0.00770745, 0.01953201,\n",
      "       0.05447741, 0.00084658, 0.00141845, 0.00230832, 0.00360355,\n",
      "       0.00985866, 0.02265735, 0.05880437]), 'std_score_time': array([0.        , 0.00603924, 0.00625048, 0.00701442, 0.00233939,\n",
      "       0.00669956, 0.01079872, 0.00126704, 0.00404399, 0.00097465,\n",
      "       0.00214663, 0.0054815 , 0.00695895, 0.01171014, 0.00080821,\n",
      "       0.00091015, 0.00098143, 0.00449245, 0.0016341 , 0.00623636,\n",
      "       0.01000122, 0.00076278, 0.00122792, 0.00041971, 0.00051141,\n",
      "       0.00418697, 0.00535314, 0.01120997]), 'param_max_depth': masked_array(data=[1, 1, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 3, 3, 10, 10, 10,\n",
      "                   10, 10, 10, 10, None, None, None, None, None, None,\n",
      "                   None],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[1, 3, 10, 30, 100, 300, 1000, 1, 3, 10, 30, 100, 300,\n",
      "                   1000, 1, 3, 10, 30, 100, 300, 1000, 1, 3, 10, 30, 100,\n",
      "                   300, 1000],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1, 'n_estimators': 1}, {'max_depth': 1, 'n_estimators': 3}, {'max_depth': 1, 'n_estimators': 10}, {'max_depth': 1, 'n_estimators': 30}, {'max_depth': 1, 'n_estimators': 100}, {'max_depth': 1, 'n_estimators': 300}, {'max_depth': 1, 'n_estimators': 1000}, {'max_depth': 3, 'n_estimators': 1}, {'max_depth': 3, 'n_estimators': 3}, {'max_depth': 3, 'n_estimators': 10}, {'max_depth': 3, 'n_estimators': 30}, {'max_depth': 3, 'n_estimators': 100}, {'max_depth': 3, 'n_estimators': 300}, {'max_depth': 3, 'n_estimators': 1000}, {'max_depth': 10, 'n_estimators': 1}, {'max_depth': 10, 'n_estimators': 3}, {'max_depth': 10, 'n_estimators': 10}, {'max_depth': 10, 'n_estimators': 30}, {'max_depth': 10, 'n_estimators': 100}, {'max_depth': 10, 'n_estimators': 300}, {'max_depth': 10, 'n_estimators': 1000}, {'max_depth': None, 'n_estimators': 1}, {'max_depth': None, 'n_estimators': 3}, {'max_depth': None, 'n_estimators': 10}, {'max_depth': None, 'n_estimators': 30}, {'max_depth': None, 'n_estimators': 100}, {'max_depth': None, 'n_estimators': 300}, {'max_depth': None, 'n_estimators': 1000}], 'split0_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.95873786, 0.9538835 , 0.9223301 ,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.91019417, 0.94902913,\n",
      "       0.95631068, 0.96601942, 0.96359223, 0.97815534, 0.98058252,\n",
      "       0.98058252, 0.95145631, 0.96359223, 0.97815534, 0.97815534,\n",
      "       0.98058252, 0.97815534, 0.97815534]), 'split1_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.9368932 , 0.93446602, 0.91747573,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.94417476,\n",
      "       0.96359223, 0.97330097, 0.97572816, 0.98058252, 0.98058252,\n",
      "       0.98300971, 0.9684466 , 0.96359223, 0.98058252, 0.98058252,\n",
      "       0.98300971, 0.98300971, 0.98300971]), 'split2_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.93446602, 0.96601942, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.94174757,\n",
      "       0.9538835 , 0.95873786, 0.95145631, 0.96601942, 0.9684466 ,\n",
      "       0.96359223, 0.93932039, 0.95873786, 0.96359223, 0.96359223,\n",
      "       0.96601942, 0.96601942, 0.96601942]), 'split3_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.97087379, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.95631068,\n",
      "       0.94902913, 0.94174757, 0.97087379, 0.96601942, 0.96601942,\n",
      "       0.9684466 , 0.95631068, 0.94660194, 0.96116505, 0.97330097,\n",
      "       0.96601942, 0.97087379, 0.97087379]), 'split4_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.97330097, 0.94417476, 0.91747573,\n",
      "       0.91504854, 0.91504854, 0.91504854, 0.91504854, 0.96116505,\n",
      "       0.97815534, 0.96359223, 0.98543689, 0.98543689, 0.98543689,\n",
      "       0.98300971, 0.95145631, 0.96359223, 0.97087379, 0.97572816,\n",
      "       0.98543689, 0.98300971, 0.98300971]), 'mean_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.95485437, 0.94126214, 0.91456311,\n",
      "       0.9092233 , 0.9092233 , 0.9092233 , 0.90970874, 0.95048544,\n",
      "       0.96019417, 0.96067961, 0.96941748, 0.97524272, 0.97621359,\n",
      "       0.97572816, 0.95339806, 0.9592233 , 0.97087379, 0.97427184,\n",
      "       0.97621359, 0.97621359, 0.97621359]), 'std_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.01643331, 0.01974243, 0.00582524,\n",
      "       0.00291262, 0.00291262, 0.00291262, 0.00283056, 0.00729772,\n",
      "       0.01013622, 0.01056871, 0.01144643, 0.00788742, 0.00758277,\n",
      "       0.00812291, 0.0093879 , 0.00658479, 0.00767543, 0.00586556,\n",
      "       0.00846388, 0.00676135, 0.00676135]), 'rank_test_score': array([22, 22, 22, 22, 22, 22, 22, 13, 16, 17, 19, 19, 19, 18, 15, 11, 10,\n",
      "        9,  6,  1,  5, 14, 12,  8,  7,  4,  1,  1])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.908 (+/-0.0) for {'max_depth': 1, 'n_estimators': 1}\n",
      "0.908 (+/-0.0) for {'max_depth': 1, 'n_estimators': 3}\n",
      "0.908 (+/-0.0) for {'max_depth': 1, 'n_estimators': 10}\n",
      "0.908 (+/-0.0) for {'max_depth': 1, 'n_estimators': 30}\n",
      "0.908 (+/-0.0) for {'max_depth': 1, 'n_estimators': 100}\n",
      "0.908 (+/-0.0) for {'max_depth': 1, 'n_estimators': 300}\n",
      "0.908 (+/-0.0) for {'max_depth': 1, 'n_estimators': 1000}\n",
      "0.955 (+/-0.033) for {'max_depth': 3, 'n_estimators': 1}\n",
      "0.941 (+/-0.039) for {'max_depth': 3, 'n_estimators': 3}\n",
      "0.915 (+/-0.012) for {'max_depth': 3, 'n_estimators': 10}\n",
      "0.909 (+/-0.006) for {'max_depth': 3, 'n_estimators': 30}\n",
      "0.909 (+/-0.006) for {'max_depth': 3, 'n_estimators': 100}\n",
      "0.909 (+/-0.006) for {'max_depth': 3, 'n_estimators': 300}\n",
      "0.91 (+/-0.006) for {'max_depth': 3, 'n_estimators': 1000}\n",
      "0.95 (+/-0.015) for {'max_depth': 10, 'n_estimators': 1}\n",
      "0.96 (+/-0.02) for {'max_depth': 10, 'n_estimators': 3}\n",
      "0.961 (+/-0.021) for {'max_depth': 10, 'n_estimators': 10}\n",
      "0.969 (+/-0.023) for {'max_depth': 10, 'n_estimators': 30}\n",
      "0.975 (+/-0.016) for {'max_depth': 10, 'n_estimators': 100}\n",
      "0.976 (+/-0.015) for {'max_depth': 10, 'n_estimators': 300}\n",
      "0.976 (+/-0.016) for {'max_depth': 10, 'n_estimators': 1000}\n",
      "0.953 (+/-0.019) for {'max_depth': None, 'n_estimators': 1}\n",
      "0.959 (+/-0.013) for {'max_depth': None, 'n_estimators': 3}\n",
      "0.971 (+/-0.015) for {'max_depth': None, 'n_estimators': 10}\n",
      "0.974 (+/-0.012) for {'max_depth': None, 'n_estimators': 30}\n",
      "0.976 (+/-0.017) for {'max_depth': None, 'n_estimators': 100}\n",
      "0.976 (+/-0.014) for {'max_depth': None, 'n_estimators': 300}\n",
      "0.976 (+/-0.014) for {'max_depth': None, 'n_estimators': 1000}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.976\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'max_depth': 10, 'n_estimators': 300}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        51\n",
      "           1       0.99      0.99      0.99       464\n",
      "\n",
      "    accuracy                           0.98       515\n",
      "   macro avg       0.96      0.96      0.96       515\n",
      "weighted avg       0.98      0.98      0.98       515\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[ 47   4]\n",
      " [  4 460]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.977,\n",
       " 'Logistic Regression': 0.981,\n",
       " 'Decision Trees': 0.984,\n",
       " 'Random Forest': 0.984}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"n_estimators\": [1, 3, 10, 30, 100, 300, 1000], \"max_depth\": [1, 3, 10, None]}]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = GridSearchCV(RandomForestClassifier(random_state=0), param_grid, cv=cv)\n",
    "rfc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, rfc)\n",
    "summary[\"Random Forest\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f914bcde-afdb-4ea0-93a5-4cc2fe2f9d39",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da015f64-7132-4a20-938c-4de52f430753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\12039\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\12039\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: scipy in c:\\users\\12039\\appdata\\roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages (from xgboost) (1.9.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12a311c8-7eec-4795-9a42-9c30d3355ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.1130373 , 0.14187942, 0.14954667, 0.12888403, 0.11604834,\n",
      "       0.12043781, 0.10330896, 0.09135966, 0.08243527]), 'std_fit_time': array([0.01945688, 0.02852218, 0.01881684, 0.01685347, 0.01501404,\n",
      "       0.01604299, 0.01589976, 0.00479991, 0.01465727]), 'mean_score_time': array([0.01621847, 0.01325006, 0.01639891, 0.01352401, 0.01162391,\n",
      "       0.01660552, 0.01275711, 0.01431332, 0.01674809]), 'std_score_time': array([0.00322604, 0.00202875, 0.00225777, 0.00729055, 0.00584835,\n",
      "       0.00350476, 0.00332742, 0.00113321, 0.0040089 ]), 'param_reg_alpha': masked_array(data=[0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'reg_alpha': 0.001}, {'reg_alpha': 0.003}, {'reg_alpha': 0.01}, {'reg_alpha': 0.03}, {'reg_alpha': 0.1}, {'reg_alpha': 0.3}, {'reg_alpha': 1}, {'reg_alpha': 3}, {'reg_alpha': 10}], 'split0_test_score': array([0.98058252, 0.98058252, 0.98058252, 0.98058252, 0.98058252,\n",
      "       0.98058252, 0.98058252, 0.98543689, 0.98543689]), 'split1_test_score': array([0.98543689, 0.98786408, 0.98543689, 0.98543689, 0.98543689,\n",
      "       0.98543689, 0.98786408, 0.98543689, 0.98300971]), 'split2_test_score': array([0.98058252, 0.98058252, 0.98058252, 0.98058252, 0.98058252,\n",
      "       0.98058252, 0.98543689, 0.97572816, 0.9684466 ]), 'split3_test_score': array([0.98300971, 0.98300971, 0.97815534, 0.98058252, 0.98300971,\n",
      "       0.98058252, 0.97572816, 0.97330097, 0.97330097]), 'split4_test_score': array([0.98786408, 0.98058252, 0.98300971, 0.98543689, 0.98058252,\n",
      "       0.98543689, 0.98058252, 0.98058252, 0.98543689]), 'mean_test_score': array([0.98349515, 0.98252427, 0.9815534 , 0.98252427, 0.98203883,\n",
      "       0.98252427, 0.98203883, 0.98009709, 0.97912621]), 'std_test_score': array([0.00283056, 0.00283056, 0.00247525, 0.00237815, 0.00194175,\n",
      "       0.00237815, 0.00423194, 0.0049505 , 0.00696733]), 'rank_test_score': array([1, 2, 7, 3, 6, 3, 5, 8, 9])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.983 (+/-0.006) for {'reg_alpha': 0.001}\n",
      "0.983 (+/-0.006) for {'reg_alpha': 0.003}\n",
      "0.982 (+/-0.005) for {'reg_alpha': 0.01}\n",
      "0.983 (+/-0.005) for {'reg_alpha': 0.03}\n",
      "0.982 (+/-0.004) for {'reg_alpha': 0.1}\n",
      "0.983 (+/-0.005) for {'reg_alpha': 0.3}\n",
      "0.982 (+/-0.008) for {'reg_alpha': 1}\n",
      "0.98 (+/-0.01) for {'reg_alpha': 3}\n",
      "0.979 (+/-0.014) for {'reg_alpha': 10}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.983\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'reg_alpha': 0.001}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93        51\n",
      "           1       1.00      0.98      0.99       464\n",
      "\n",
      "    accuracy                           0.98       515\n",
      "   macro avg       0.94      0.98      0.96       515\n",
      "weighted avg       0.99      0.98      0.98       515\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[ 50   1]\n",
      " [  7 457]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.984\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.977,\n",
       " 'Logistic Regression': 0.981,\n",
       " 'Decision Trees': 0.984,\n",
       " 'Random Forest': 0.984,\n",
       " 'XGBoost': 0.984}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"reg_alpha\": [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, 10]}]\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgbc = GridSearchCV(XGBClassifier(random_state=0), param_grid, cv=cv)\n",
    "xgbc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, xgbc)\n",
    "summary[\"XGBoost\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1b103c-d597-4344-b7f2-76d6f8d36919",
   "metadata": {},
   "source": [
    "### Linear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5ada107-7827-44f2-b05c-65a887a59815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.03833652, 0.02500749, 0.02362008, 0.02557769, 0.02411084,\n",
      "       0.02492094, 0.02203889]), 'std_fit_time': array([0.01796566, 0.00203721, 0.00710845, 0.00574328, 0.00383864,\n",
      "       0.0073067 , 0.00630081]), 'mean_score_time': array([0.00468102, 0.00181561, 0.00071812, 0.00213699, 0.00020094,\n",
      "       0.00209727, 0.00039778]), 'std_score_time': array([0.00559927, 0.00041196, 0.00089638, 0.00288206, 0.00040188,\n",
      "       0.00371504, 0.00048718]), 'param_C': masked_array(data=[0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.01}, {'C': 0.03}, {'C': 0.1}, {'C': 0.3}, {'C': 1}, {'C': 3}, {'C': 10}], 'split0_test_score': array([0.97572816, 0.98300971, 0.98543689, 0.98543689, 0.98300971,\n",
      "       0.84223301, 0.9684466 ]), 'split1_test_score': array([0.97815534, 0.98786408, 0.99271845, 0.98543689, 0.98786408,\n",
      "       0.9684466 , 0.98300971]), 'split2_test_score': array([0.98300971, 0.98786408, 0.97572816, 0.98543689, 0.98543689,\n",
      "       0.9223301 , 0.98058252]), 'split3_test_score': array([0.96359223, 0.97572816, 0.97572816, 0.97330097, 0.96116505,\n",
      "       0.97572816, 0.95873786]), 'split4_test_score': array([0.97572816, 0.98786408, 0.97572816, 0.97330097, 0.94902913,\n",
      "       0.92961165, 0.96116505]), 'mean_test_score': array([0.97524272, 0.98446602, 0.98106796, 0.98058252, 0.97330097,\n",
      "       0.9276699 , 0.97038835]), 'std_test_score': array([0.00640335, 0.00475629, 0.00693343, 0.00594536, 0.01542743,\n",
      "       0.04754804, 0.00987718]), 'rank_test_score': array([4, 1, 2, 3, 5, 7, 6])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.975 (+/-0.013) for {'C': 0.01}\n",
      "0.984 (+/-0.01) for {'C': 0.03}\n",
      "0.981 (+/-0.014) for {'C': 0.1}\n",
      "0.981 (+/-0.012) for {'C': 0.3}\n",
      "0.973 (+/-0.031) for {'C': 1}\n",
      "0.928 (+/-0.095) for {'C': 3}\n",
      "0.97 (+/-0.02) for {'C': 10}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.984\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'C': 0.03}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        51\n",
      "           1       0.99      0.99      0.99       464\n",
      "\n",
      "    accuracy                           0.98       515\n",
      "   macro avg       0.96      0.96      0.96       515\n",
      "weighted avg       0.98      0.98      0.98       515\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[ 47   4]\n",
      " [  4 460]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.977,\n",
       " 'Logistic Regression': 0.981,\n",
       " 'Decision Trees': 0.984,\n",
       " 'Random Forest': 0.984,\n",
       " 'XGBoost': 0.984,\n",
       " 'Linear SVMs': 0.984}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10]}]\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "lsvc = GridSearchCV(LinearSVC(random_state=0), param_grid, cv=cv)\n",
    "lsvc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, lsvc)\n",
    "summary[\"Linear SVMs\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a821b11-593d-4976-af23-0be8d49ff1b6",
   "metadata": {},
   "source": [
    "### Kernelized SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cd4055ca-5169-48b7-bbea-66e42899598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.01780486, 0.02395916, 0.02356901, 0.02914762, 0.06726851,\n",
      "       0.11187234, 0.15738688, 0.16878867, 0.15957336, 0.02065668,\n",
      "       0.03889852, 0.02845898, 0.04265308, 0.11227832, 0.15953646,\n",
      "       0.15887265, 0.16355324, 0.17355008, 0.02593637, 0.05287504,\n",
      "       0.03190427, 0.04894972, 0.10629511, 0.15601697, 0.20609956,\n",
      "       0.17780666, 0.17231326, 0.02025018, 0.04777827, 0.03140669,\n",
      "       0.05070033, 0.1086484 , 0.15955453, 0.16934776, 0.16170459,\n",
      "       0.16010933, 0.01397862, 0.03318515, 0.01519613, 0.04782705,\n",
      "       0.11947193, 0.14459167, 0.14990149, 0.15316706, 0.14381223,\n",
      "       0.01704435, 0.03050818, 0.02194233, 0.04325247, 0.11685486,\n",
      "       0.14047647, 0.14447622, 0.14342546, 0.15104814, 0.01062956,\n",
      "       0.02824121, 0.02301712, 0.0398746 , 0.11783056, 0.14356542,\n",
      "       0.14058533, 0.15177732, 0.14786854]), 'std_fit_time': array([0.00842172, 0.00970868, 0.00533625, 0.00894393, 0.00593101,\n",
      "       0.00696816, 0.01222586, 0.03367584, 0.02269604, 0.00072469,\n",
      "       0.02426142, 0.00824674, 0.00254672, 0.01972627, 0.03144388,\n",
      "       0.01501761, 0.01739109, 0.01646415, 0.00493335, 0.00781551,\n",
      "       0.00725909, 0.0082615 , 0.00738823, 0.02131271, 0.05567383,\n",
      "       0.02347125, 0.01869481, 0.00474741, 0.01432835, 0.00455254,\n",
      "       0.00407125, 0.00920762, 0.01258417, 0.03236561, 0.01037732,\n",
      "       0.00608653, 0.00178793, 0.00217301, 0.00117788, 0.00445973,\n",
      "       0.00916211, 0.00491656, 0.01082872, 0.01272795, 0.0045812 ,\n",
      "       0.00216147, 0.0034484 , 0.00102589, 0.00055622, 0.00572231,\n",
      "       0.00973094, 0.00634306, 0.00325896, 0.00768831, 0.00614688,\n",
      "       0.00625828, 0.00702197, 0.00818694, 0.00668384, 0.00680076,\n",
      "       0.00229455, 0.01533117, 0.00695472]), 'mean_score_time': array([0.01326337, 0.01444702, 0.01126032, 0.01731882, 0.02256608,\n",
      "       0.0434113 , 0.06437006, 0.08330207, 0.07378907, 0.01128502,\n",
      "       0.02143059, 0.01207323, 0.02200561, 0.04962234, 0.06505146,\n",
      "       0.063659  , 0.05991526, 0.07698321, 0.01366224, 0.0239429 ,\n",
      "       0.01291437, 0.02370424, 0.04254813, 0.06567926, 0.08349938,\n",
      "       0.06671128, 0.07424307, 0.00578833, 0.0215281 , 0.01513247,\n",
      "       0.02288656, 0.04117413, 0.05849266, 0.06327391, 0.06170993,\n",
      "       0.06637726, 0.00839047, 0.00939388, 0.01666441, 0.01729774,\n",
      "       0.03925371, 0.04637055, 0.06357403, 0.06326661, 0.06613054,\n",
      "       0.00608425, 0.01523814, 0.00968704, 0.01796479, 0.03863893,\n",
      "       0.05414205, 0.06259613, 0.06028466, 0.05485392, 0.00574007,\n",
      "       0.00949225, 0.0052484 , 0.01396337, 0.0352293 , 0.0535562 ,\n",
      "       0.06016493, 0.06200013, 0.05562806]), 'std_score_time': array([0.00215716, 0.00708617, 0.00592867, 0.00231801, 0.00553673,\n",
      "       0.0029603 , 0.00750059, 0.01233822, 0.00481488, 0.00066518,\n",
      "       0.00739886, 0.00342581, 0.00769346, 0.00406933, 0.00982984,\n",
      "       0.00426151, 0.00481149, 0.00610854, 0.00516694, 0.00638669,\n",
      "       0.00328927, 0.00685115, 0.00259128, 0.00396481, 0.02756198,\n",
      "       0.00708319, 0.00798348, 0.00475712, 0.00598327, 0.00856829,\n",
      "       0.00407936, 0.00751367, 0.00610422, 0.00810126, 0.00585489,\n",
      "       0.00282067, 0.00674526, 0.00637437, 0.00106312, 0.00199917,\n",
      "       0.00722345, 0.0009897 , 0.0079829 , 0.00275886, 0.00390977,\n",
      "       0.00645944, 0.00412838, 0.00070822, 0.00216609, 0.00767385,\n",
      "       0.00744287, 0.00131916, 0.00637238, 0.00958222, 0.00707854,\n",
      "       0.00775371, 0.00662013, 0.00355954, 0.00595915, 0.00871427,\n",
      "       0.00633866, 0.00783841, 0.00624949]), 'param_C': masked_array(data=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
      "                   0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03, 0.03,\n",
      "                   0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.3, 0.3,\n",
      "                   0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 0.3, 1, 1, 1, 1, 1, 1, 1,\n",
      "                   1, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 10, 10, 10, 10, 10,\n",
      "                   10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=['scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10,\n",
      "                   'scale', 'auto', 0.01, 0.03, 0.1, 0.3, 1, 3, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.01, 'gamma': 'scale'}, {'C': 0.01, 'gamma': 'auto'}, {'C': 0.01, 'gamma': 0.01}, {'C': 0.01, 'gamma': 0.03}, {'C': 0.01, 'gamma': 0.1}, {'C': 0.01, 'gamma': 0.3}, {'C': 0.01, 'gamma': 1}, {'C': 0.01, 'gamma': 3}, {'C': 0.01, 'gamma': 10}, {'C': 0.03, 'gamma': 'scale'}, {'C': 0.03, 'gamma': 'auto'}, {'C': 0.03, 'gamma': 0.01}, {'C': 0.03, 'gamma': 0.03}, {'C': 0.03, 'gamma': 0.1}, {'C': 0.03, 'gamma': 0.3}, {'C': 0.03, 'gamma': 1}, {'C': 0.03, 'gamma': 3}, {'C': 0.03, 'gamma': 10}, {'C': 0.1, 'gamma': 'scale'}, {'C': 0.1, 'gamma': 'auto'}, {'C': 0.1, 'gamma': 0.01}, {'C': 0.1, 'gamma': 0.03}, {'C': 0.1, 'gamma': 0.1}, {'C': 0.1, 'gamma': 0.3}, {'C': 0.1, 'gamma': 1}, {'C': 0.1, 'gamma': 3}, {'C': 0.1, 'gamma': 10}, {'C': 0.3, 'gamma': 'scale'}, {'C': 0.3, 'gamma': 'auto'}, {'C': 0.3, 'gamma': 0.01}, {'C': 0.3, 'gamma': 0.03}, {'C': 0.3, 'gamma': 0.1}, {'C': 0.3, 'gamma': 0.3}, {'C': 0.3, 'gamma': 1}, {'C': 0.3, 'gamma': 3}, {'C': 0.3, 'gamma': 10}, {'C': 1, 'gamma': 'scale'}, {'C': 1, 'gamma': 'auto'}, {'C': 1, 'gamma': 0.01}, {'C': 1, 'gamma': 0.03}, {'C': 1, 'gamma': 0.1}, {'C': 1, 'gamma': 0.3}, {'C': 1, 'gamma': 1}, {'C': 1, 'gamma': 3}, {'C': 1, 'gamma': 10}, {'C': 3, 'gamma': 'scale'}, {'C': 3, 'gamma': 'auto'}, {'C': 3, 'gamma': 0.01}, {'C': 3, 'gamma': 0.03}, {'C': 3, 'gamma': 0.1}, {'C': 3, 'gamma': 0.3}, {'C': 3, 'gamma': 1}, {'C': 3, 'gamma': 3}, {'C': 3, 'gamma': 10}, {'C': 10, 'gamma': 'scale'}, {'C': 10, 'gamma': 'auto'}, {'C': 10, 'gamma': 0.01}, {'C': 10, 'gamma': 0.03}, {'C': 10, 'gamma': 0.1}, {'C': 10, 'gamma': 0.3}, {'C': 10, 'gamma': 1}, {'C': 10, 'gamma': 3}, {'C': 10, 'gamma': 10}], 'split0_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.91990291, 0.90776699,\n",
      "       0.92961165, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.94902913, 0.97572816, 0.97572816,\n",
      "       0.94660194, 0.91504854, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.96359223, 0.97572816, 0.98058252, 0.97087379,\n",
      "       0.94902913, 0.91504854, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.97815534, 0.97572816, 0.97572816, 0.97330097, 0.94660194,\n",
      "       0.91504854, 0.90776699, 0.90776699, 0.90776699, 0.98300971,\n",
      "       0.97815534, 0.98058252, 0.96601942, 0.94660194, 0.91504854,\n",
      "       0.90776699, 0.90776699, 0.90776699]), 'split1_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.9223301 , 0.91019417,\n",
      "       0.92475728, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.9538835 , 0.9684466 , 0.97815534,\n",
      "       0.94417476, 0.91504854, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.9684466 , 0.97572816, 0.97572816, 0.9684466 ,\n",
      "       0.93932039, 0.91747573, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.98300971, 0.97572816, 0.98058252, 0.97572816, 0.95631068,\n",
      "       0.91747573, 0.90776699, 0.90776699, 0.90776699, 0.98300971,\n",
      "       0.97815534, 0.97572816, 0.97815534, 0.95631068, 0.91747573,\n",
      "       0.90776699, 0.90776699, 0.90776699]), 'split2_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.91504854, 0.91019417,\n",
      "       0.91262136, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.94417476, 0.9538835 , 0.97087379,\n",
      "       0.92718447, 0.91019417, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.95145631, 0.97087379, 0.97087379, 0.96601942,\n",
      "       0.92475728, 0.91262136, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.96359223, 0.9684466 , 0.97087379, 0.9684466 , 0.93932039,\n",
      "       0.91019417, 0.90776699, 0.90776699, 0.90776699, 0.9684466 ,\n",
      "       0.97572816, 0.9684466 , 0.97572816, 0.93932039, 0.91019417,\n",
      "       0.90776699, 0.90776699, 0.90776699]), 'split3_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.91019417, 0.91990291,\n",
      "       0.92718447, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.93446602, 0.95631068, 0.95631068,\n",
      "       0.91990291, 0.91262136, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.9538835 , 0.96359223, 0.9684466 , 0.96116505,\n",
      "       0.93203883, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.97087379, 0.96116505, 0.96359223, 0.96359223, 0.94417476,\n",
      "       0.91262136, 0.90776699, 0.90776699, 0.90776699, 0.97087379,\n",
      "       0.96601942, 0.9684466 , 0.97087379, 0.94417476, 0.91262136,\n",
      "       0.90776699, 0.90776699, 0.90776699]), 'split4_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.9223301 , 0.91019417,\n",
      "       0.92961165, 0.91019417, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.94660194, 0.97087379, 0.98058252,\n",
      "       0.94174757, 0.91019417, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.97087379, 0.98058252, 0.98300971, 0.97815534,\n",
      "       0.94174757, 0.91262136, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.98543689, 0.98058252, 0.98300971, 0.97572816, 0.94174757,\n",
      "       0.91747573, 0.90776699, 0.90776699, 0.90776699, 0.98543689,\n",
      "       0.98058252, 0.98543689, 0.97815534, 0.94417476, 0.91747573,\n",
      "       0.90776699, 0.90776699, 0.90776699]), 'mean_test_score': array([0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.90776699, 0.91796117, 0.91165049,\n",
      "       0.92475728, 0.90825243, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.90776699, 0.94563107, 0.96504854, 0.9723301 ,\n",
      "       0.93592233, 0.91262136, 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.90776699, 0.96165049, 0.97330097, 0.97572816, 0.96893204,\n",
      "       0.93737864, 0.9131068 , 0.90776699, 0.90776699, 0.90776699,\n",
      "       0.97621359, 0.9723301 , 0.97475728, 0.97135922, 0.94563107,\n",
      "       0.91456311, 0.90776699, 0.90776699, 0.90776699, 0.97815534,\n",
      "       0.97572816, 0.97572816, 0.97378641, 0.9461165 , 0.91456311,\n",
      "       0.90776699, 0.90776699, 0.90776699]), 'std_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.        , 0.00470649, 0.00423194,\n",
      "       0.00632932, 0.00097087, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.        , 0.00644005, 0.00849168, 0.00862931,\n",
      "       0.01047914, 0.00217094, 0.        , 0.        , 0.        ,\n",
      "       0.        , 0.00773659, 0.00574377, 0.00553483, 0.00561934,\n",
      "       0.00832351, 0.00322002, 0.        , 0.        , 0.        ,\n",
      "       0.00803541, 0.00679612, 0.00696733, 0.00470649, 0.00586556,\n",
      "       0.00283056, 0.        , 0.        , 0.        , 0.00703465,\n",
      "       0.00509131, 0.00669129, 0.00470649, 0.00561934, 0.00283056,\n",
      "       0.        , 0.        , 0.        ]), 'rank_test_score': array([28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28,\n",
      "       28, 21, 26, 20, 27, 28, 28, 28, 28, 28, 16, 13,  9, 19, 25, 28, 28,\n",
      "       28, 28, 14,  8,  3, 12, 18, 24, 28, 28, 28,  2,  9,  6, 11, 16, 22,\n",
      "       28, 28, 28,  1,  3,  3,  7, 15, 22, 28, 28, 28])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.908 (+/-0.0) for {'C': 0.01, 'gamma': 'scale'}\n",
      "0.908 (+/-0.0) for {'C': 0.01, 'gamma': 'auto'}\n",
      "0.908 (+/-0.0) for {'C': 0.01, 'gamma': 0.01}\n",
      "0.908 (+/-0.0) for {'C': 0.01, 'gamma': 0.03}\n",
      "0.908 (+/-0.0) for {'C': 0.01, 'gamma': 0.1}\n",
      "0.908 (+/-0.0) for {'C': 0.01, 'gamma': 0.3}\n",
      "0.908 (+/-0.0) for {'C': 0.01, 'gamma': 1}\n",
      "0.908 (+/-0.0) for {'C': 0.01, 'gamma': 3}\n",
      "0.908 (+/-0.0) for {'C': 0.01, 'gamma': 10}\n",
      "0.908 (+/-0.0) for {'C': 0.03, 'gamma': 'scale'}\n",
      "0.908 (+/-0.0) for {'C': 0.03, 'gamma': 'auto'}\n",
      "0.908 (+/-0.0) for {'C': 0.03, 'gamma': 0.01}\n",
      "0.908 (+/-0.0) for {'C': 0.03, 'gamma': 0.03}\n",
      "0.908 (+/-0.0) for {'C': 0.03, 'gamma': 0.1}\n",
      "0.908 (+/-0.0) for {'C': 0.03, 'gamma': 0.3}\n",
      "0.908 (+/-0.0) for {'C': 0.03, 'gamma': 1}\n",
      "0.908 (+/-0.0) for {'C': 0.03, 'gamma': 3}\n",
      "0.908 (+/-0.0) for {'C': 0.03, 'gamma': 10}\n",
      "0.918 (+/-0.009) for {'C': 0.1, 'gamma': 'scale'}\n",
      "0.912 (+/-0.008) for {'C': 0.1, 'gamma': 'auto'}\n",
      "0.925 (+/-0.013) for {'C': 0.1, 'gamma': 0.01}\n",
      "0.908 (+/-0.002) for {'C': 0.1, 'gamma': 0.03}\n",
      "0.908 (+/-0.0) for {'C': 0.1, 'gamma': 0.1}\n",
      "0.908 (+/-0.0) for {'C': 0.1, 'gamma': 0.3}\n",
      "0.908 (+/-0.0) for {'C': 0.1, 'gamma': 1}\n",
      "0.908 (+/-0.0) for {'C': 0.1, 'gamma': 3}\n",
      "0.908 (+/-0.0) for {'C': 0.1, 'gamma': 10}\n",
      "0.946 (+/-0.013) for {'C': 0.3, 'gamma': 'scale'}\n",
      "0.965 (+/-0.017) for {'C': 0.3, 'gamma': 'auto'}\n",
      "0.972 (+/-0.017) for {'C': 0.3, 'gamma': 0.01}\n",
      "0.936 (+/-0.021) for {'C': 0.3, 'gamma': 0.03}\n",
      "0.913 (+/-0.004) for {'C': 0.3, 'gamma': 0.1}\n",
      "0.908 (+/-0.0) for {'C': 0.3, 'gamma': 0.3}\n",
      "0.908 (+/-0.0) for {'C': 0.3, 'gamma': 1}\n",
      "0.908 (+/-0.0) for {'C': 0.3, 'gamma': 3}\n",
      "0.908 (+/-0.0) for {'C': 0.3, 'gamma': 10}\n",
      "0.962 (+/-0.015) for {'C': 1, 'gamma': 'scale'}\n",
      "0.973 (+/-0.011) for {'C': 1, 'gamma': 'auto'}\n",
      "0.976 (+/-0.011) for {'C': 1, 'gamma': 0.01}\n",
      "0.969 (+/-0.011) for {'C': 1, 'gamma': 0.03}\n",
      "0.937 (+/-0.017) for {'C': 1, 'gamma': 0.1}\n",
      "0.913 (+/-0.006) for {'C': 1, 'gamma': 0.3}\n",
      "0.908 (+/-0.0) for {'C': 1, 'gamma': 1}\n",
      "0.908 (+/-0.0) for {'C': 1, 'gamma': 3}\n",
      "0.908 (+/-0.0) for {'C': 1, 'gamma': 10}\n",
      "0.976 (+/-0.016) for {'C': 3, 'gamma': 'scale'}\n",
      "0.972 (+/-0.014) for {'C': 3, 'gamma': 'auto'}\n",
      "0.975 (+/-0.014) for {'C': 3, 'gamma': 0.01}\n",
      "0.971 (+/-0.009) for {'C': 3, 'gamma': 0.03}\n",
      "0.946 (+/-0.012) for {'C': 3, 'gamma': 0.1}\n",
      "0.915 (+/-0.006) for {'C': 3, 'gamma': 0.3}\n",
      "0.908 (+/-0.0) for {'C': 3, 'gamma': 1}\n",
      "0.908 (+/-0.0) for {'C': 3, 'gamma': 3}\n",
      "0.908 (+/-0.0) for {'C': 3, 'gamma': 10}\n",
      "0.978 (+/-0.014) for {'C': 10, 'gamma': 'scale'}\n",
      "0.976 (+/-0.01) for {'C': 10, 'gamma': 'auto'}\n",
      "0.976 (+/-0.013) for {'C': 10, 'gamma': 0.01}\n",
      "0.974 (+/-0.009) for {'C': 10, 'gamma': 0.03}\n",
      "0.946 (+/-0.011) for {'C': 10, 'gamma': 0.1}\n",
      "0.915 (+/-0.006) for {'C': 10, 'gamma': 0.3}\n",
      "0.908 (+/-0.0) for {'C': 10, 'gamma': 1}\n",
      "0.908 (+/-0.0) for {'C': 10, 'gamma': 3}\n",
      "0.908 (+/-0.0) for {'C': 10, 'gamma': 10}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.978\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'C': 10, 'gamma': 'scale'}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.90        51\n",
      "           1       0.99      0.98      0.99       464\n",
      "\n",
      "    accuracy                           0.98       515\n",
      "   macro avg       0.93      0.95      0.94       515\n",
      "weighted avg       0.98      0.98      0.98       515\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[ 47   4]\n",
      " [  7 457]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.979\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.977,\n",
       " 'Logistic Regression': 0.981,\n",
       " 'Decision Trees': 0.984,\n",
       " 'Random Forest': 0.984,\n",
       " 'XGBoost': 0.984,\n",
       " 'Linear SVMs': 0.984,\n",
       " 'Kernelized SVMs': 0.979}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"C\": [0.01, 0.03, 0.1, 0.3, 1, 3, 10], \"gamma\": [\"scale\", \"auto\", 0.01, 0.03, 0.1, 0.3, 1, 3, 10]}]\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc = GridSearchCV(SVC(random_state=0), param_grid, cv=cv)\n",
    "svc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, svc)\n",
    "summary[\"Kernelized SVMs\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d26db3-bb28-4410-87f2-9bd2a590e399",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb1617a3-db7f-4155-8df8-24123d0532d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Parameter estimation results: \n",
      "{'mean_fit_time': array([0.21024842, 0.53698568, 0.47766705, 0.278088  , 0.60873952,\n",
      "       1.0229547 , 2.06372037, 1.48402858, 2.05279956]), 'std_fit_time': array([0.0380602 , 0.04734976, 0.02574445, 0.0124223 , 0.0370021 ,\n",
      "       0.4433785 , 0.53403058, 0.27757331, 0.45934033]), 'mean_score_time': array([0.00104337, 0.00100107, 0.        , 0.00310683, 0.00372124,\n",
      "       0.0011734 , 0.00279121, 0.0008409 , 0.00353341]), 'std_score_time': array([0.0009329 , 0.00200214, 0.        , 0.00525887, 0.00603472,\n",
      "       0.00143784, 0.003479  , 0.00114135, 0.00442488]), 'param_hidden_layer_sizes': masked_array(data=[(10,), (10,), (10,), (30,), (30,), (30,), (100,),\n",
      "                   (100,), (100,)],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_solver': masked_array(data=['lbfgs', 'sgd', 'adam', 'lbfgs', 'sgd', 'adam',\n",
      "                   'lbfgs', 'sgd', 'adam'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}, {'hidden_layer_sizes': (10,), 'solver': 'sgd'}, {'hidden_layer_sizes': (10,), 'solver': 'adam'}, {'hidden_layer_sizes': (30,), 'solver': 'lbfgs'}, {'hidden_layer_sizes': (30,), 'solver': 'sgd'}, {'hidden_layer_sizes': (30,), 'solver': 'adam'}, {'hidden_layer_sizes': (100,), 'solver': 'lbfgs'}, {'hidden_layer_sizes': (100,), 'solver': 'sgd'}, {'hidden_layer_sizes': (100,), 'solver': 'adam'}], 'split0_test_score': array([0.98543689, 0.96359223, 0.97815534, 0.98786408, 0.9538835 ,\n",
      "       0.98058252, 0.98058252, 0.9684466 , 0.98058252]), 'split1_test_score': array([0.98786408, 0.9684466 , 0.97330097, 0.98543689, 0.96359223,\n",
      "       0.98058252, 0.98543689, 0.96601942, 0.98058252]), 'split2_test_score': array([0.98786408, 0.9538835 , 0.97330097, 0.98786408, 0.94660194,\n",
      "       0.97330097, 0.98543689, 0.95631068, 0.97815534]), 'split3_test_score': array([0.98058252, 0.94660194, 0.97087379, 0.98543689, 0.94902913,\n",
      "       0.97330097, 0.97572816, 0.95873786, 0.98058252]), 'split4_test_score': array([0.98543689, 0.94174757, 0.98543689, 0.98786408, 0.94417476,\n",
      "       0.98543689, 0.97572816, 0.94417476, 0.98058252]), 'mean_test_score': array([0.98543689, 0.95485437, 0.97621359, 0.9868932 , 0.95145631,\n",
      "       0.97864078, 0.98058252, 0.95873786, 0.98009709]), 'std_test_score': array([0.00265885, 0.0100193 , 0.00518305, 0.00118907, 0.00686511,\n",
      "       0.00470649, 0.00434188, 0.008547  , 0.00097087]), 'rank_test_score': array([2, 8, 6, 1, 9, 5, 3, 7, 4])}\n",
      "\n",
      "*** Grid scores: \n",
      "0.985 (+/-0.005) for {'hidden_layer_sizes': (10,), 'solver': 'lbfgs'}\n",
      "0.955 (+/-0.02) for {'hidden_layer_sizes': (10,), 'solver': 'sgd'}\n",
      "0.976 (+/-0.01) for {'hidden_layer_sizes': (10,), 'solver': 'adam'}\n",
      "0.987 (+/-0.002) for {'hidden_layer_sizes': (30,), 'solver': 'lbfgs'}\n",
      "0.951 (+/-0.014) for {'hidden_layer_sizes': (30,), 'solver': 'sgd'}\n",
      "0.979 (+/-0.009) for {'hidden_layer_sizes': (30,), 'solver': 'adam'}\n",
      "0.981 (+/-0.009) for {'hidden_layer_sizes': (100,), 'solver': 'lbfgs'}\n",
      "0.959 (+/-0.017) for {'hidden_layer_sizes': (100,), 'solver': 'sgd'}\n",
      "0.98 (+/-0.002) for {'hidden_layer_sizes': (100,), 'solver': 'adam'}\n",
      "\n",
      "*** Highest accuracy score: \n",
      "0.987\n",
      "\n",
      "*** Best parameters set found: \n",
      "{'hidden_layer_sizes': (30,), 'solver': 'lbfgs'}\n",
      "\n",
      "*** Classification report for the best parameters set: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        51\n",
      "           1       0.99      0.99      0.99       464\n",
      "\n",
      "    accuracy                           0.98       515\n",
      "   macro avg       0.95      0.95      0.95       515\n",
      "weighted avg       0.98      0.98      0.98       515\n",
      "\n",
      "\n",
      "*** Confusion matrix for the best parameters set: \n",
      "[[ 46   5]\n",
      " [  5 459]]\n",
      "\n",
      "*** Final accuracy score: \n",
      "0.981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\12039\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:546: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.977,\n",
       " 'Logistic Regression': 0.981,\n",
       " 'Decision Trees': 0.984,\n",
       " 'Random Forest': 0.984,\n",
       " 'XGBoost': 0.984,\n",
       " 'Linear SVMs': 0.984,\n",
       " 'Kernelized SVMs': 0.979,\n",
       " 'Neural Networks': 0.981}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{\"hidden_layer_sizes\": [(10,), (30,), (100,)], \"solver\": [\"lbfgs\", \"sgd\", \"adam\"]}]\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlpc = GridSearchCV(MLPClassifier(random_state=0), param_grid, cv=cv)\n",
    "mlpc, score = train_test2(X_train, X_test, y_train, y_test, param_grid, mlpc)\n",
    "summary[\"Neural Networks\"] = score\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3c7782-820d-424d-baa5-ea39189655ec",
   "metadata": {},
   "source": [
    "## Compare and choose model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2bcb22f4-04cf-4207-85dd-1d1fe6ec11b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'k-NNs': 0.977,\n",
       " 'Logistic Regression': 0.981,\n",
       " 'Decision Trees': 0.984,\n",
       " 'Random Forest': 0.984,\n",
       " 'XGBoost': 0.984,\n",
       " 'Linear SVMs': 0.984,\n",
       " 'Kernelized SVMs': 0.979,\n",
       " 'Neural Networks': 0.981}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5b2a9d-2eb9-482c-a412-a16bbe211bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
